{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#092321 Modify the TDAmeritrade API get refresh token algo\n",
    "#061121 Hide the TDAmeritrade API credentials\n",
    "#022021 Add controal group to compare the significance of WOO rating  \n",
    "#012721 Adjust earnings date and expiration date comparison method. \n",
    "#011221 Add code to request option contracts data in one shot\n",
    "#010721 Add time delay due to increased number of stocks and TOS limitation.\n",
    "#123120 Add try and except to report function for updating earnings date\n",
    "#121720 Replace RSI from Alpha-Vantage with local function (Alpha-Vantage does not work properly) \n",
    "#110320 Fixed bugs in RSI update frequency and XLC list building.\n",
    "#102220 Add a step to check if the algo uses the most recent data: data_test function\n",
    "#100220 Add a row of 'No Recommendations' to show if the output is empty\n",
    "#090820 Replace source of S&P 500 members' symbols\n",
    "#072720 Add Google Spreadsheet update for AppSheet\n",
    "\n",
    "# using Norgate data\n",
    "# using Yahoo Finance Earning Calendar\n",
    "\n",
    "import norgatedata\n",
    "priceadjust = norgatedata.StockPriceAdjustmentType.TOTALRETURN \n",
    "padding_setting = norgatedata.PaddingType.NONE   \n",
    "timeseriesformat = 'pandas-dataframe'\n",
    "\n",
    "#from alpha_vantage.timeseries import TimeSeries\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "#import quandl\n",
    "import sys\n",
    "import math\n",
    "from tqdm import tqdm, trange\n",
    "#from alpha_vantage.techindicators import TechIndicators\n",
    "#from datapackage import Package\n",
    "#import urllib.request, json\n",
    "#from pymemcache.client import base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "support1 = 0\n",
    "support2 = 0\n",
    "resistance1 = 0\n",
    "resistance2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef all_time_rsi_values(stock_para):\\n    ts = TechIndicators(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\\n    data, meta_data = ts.get_rsi(symbol=stock_para)\\n    return data['RSI'][-1]\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def all_time_rsi_values(stock_para):\n",
    "    ts = TechIndicators(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "    data, meta_data = ts.get_rsi(symbol=stock_para)\n",
    "    return data['RSI'][-1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "def get_earnings_date():\n",
    "    \"\"\"\n",
    "    Get earnings dates for a week from today by scraping data from https://api.earningscalendar.net/\n",
    "    \"\"\"\n",
    "    start_date = date.today()\n",
    "    end_date = date.today()+timedelta(5)\n",
    "\n",
    "    list_4_today=list()\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        time.sleep(5)\n",
    "        x=single_date.strftime(\"%Y%m%d\")\n",
    "        urlto_search=\"https://api.earningscalendar.net/?date=\"+x\n",
    "        with urllib.request.urlopen(urlto_search) as url:\n",
    "            data = json.loads(url.read().decode())\n",
    "            for dat in data:\n",
    "                list_4_today.append(dat[\"ticker\"])\n",
    "    return list_4_today\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(symbol_para):\n",
    "    symbol = symbol_para\n",
    "    start_date = '2015-01-01' #ts = TimeSeries(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "    try:\n",
    "        #print(symbol_para)\n",
    "        pricedata_dataframe = norgatedata.price_timeseries(\n",
    "                    symbol,\n",
    "                    stock_price_adjustment_setting = priceadjust,\n",
    "                    padding_setting = padding_setting,\n",
    "                    start_date = start_date,\n",
    "                    format=timeseriesformat)\n",
    "        company_name = norgatedata.security_name(symbol)[:-7]\n",
    "    except:\n",
    "        return pd.DataFrame(), str()\n",
    "    myData = pricedata_dataframe.rename(index=str, columns={\"2. high\": \"High\", \"3. low\": \"Low\",\"4. close\":\"Close\"})\n",
    "    myData['20d'] = np.round(myData.Close.rolling(window =20, center = False).mean(),2)\n",
    "    myData['50d'] = np.round(myData.Close.rolling(window =50, center = False).mean(),2)\n",
    "    myData['200d'] = np.round(myData.Close.rolling(window =200, center = False).mean(),2)\n",
    "    #print(myData.tail(5))\n",
    "    \n",
    "    return (myData, company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMA rating\n",
    "def SMA_rating(data_simple):\n",
    "#     start_date = date(1998,1,2)\n",
    "#     yesterday = (datetime.now() - timedelta(days=1))\n",
    "#     end_date = date(yesterday.year,yesterday.month,yesterday.day)\n",
    "    sma_rating = 0\n",
    "    index = len(data_simple.index)-1\n",
    "    if data_simple['Close'][index] > data_simple['50d'][index] > data_simple['200d'][index]:\n",
    "        sma_rating=1\n",
    "    elif data_simple['50d'][index] > data_simple['Close'][index]> data_simple['200d'][index]:\n",
    "        sma_rating=2\n",
    "    elif data_simple['50d'][index] > data_simple['200d'][index] > data_simple['Close'][index]:\n",
    "        sma_rating=3\n",
    "    elif data_simple['200d'][index] > data_simple['50d'][index] > data_simple['Close'][index]:\n",
    "        sma_rating=4\n",
    "    elif data_simple['200d'][index]> data_simple['Close'][index] > data_simple['50d'][index]:\n",
    "        sma_rating=5\n",
    "    elif data_simple['Close'][index] > data_simple['200d'][index] > data_simple['50d'][index]:\n",
    "        sma_rating=6\n",
    "    elif data_simple['Close'][index] > data_simple['50d'][index] > data_simple['200d'][index]:\n",
    "        sma_rating=7\n",
    "    return sma_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD_rating(data_simple):\n",
    "        data_simple['26 ema']=data_simple.Close.ewm(span=26).mean()\n",
    "        data_simple['12 ema']=data_simple.Close.ewm(span=12).mean()\n",
    "        data_simple['MACD'] = (data_simple['12 ema'] - data_simple['26 ema'])\n",
    "        data_simple['signal_line']=data_simple.MACD.ewm(span=9).mean()\n",
    "        data_simple['hist']=(data_simple['MACD']-data_simple['signal_line'])\n",
    "        \n",
    "        #MACD rating\n",
    "        index = len(data_simple)-1\n",
    "        slope = 0\n",
    "        macd_rating = 0\n",
    "        \n",
    "        #print(\"Current MACD:\",data_simple['MACD'][index])\n",
    "        #print(\"Previous day MACD\",data_simple['MACD'][index-1])\n",
    "        \n",
    "        #Condition for the slope\n",
    "        if((data_simple['MACD'][index] - data_simple['MACD'][index-1])>0):\n",
    "            slope = 1\n",
    "        elif((data_simple['MACD'][index] - data_simple['MACD'][index-1])<0):\n",
    "            slope = -1\n",
    "            \n",
    "        #Condition for the MACD rating\n",
    "        if data_simple['MACD'][index] > data_simple['signal_line'][index] and data_simple['signal_line'][index] > 0:\n",
    "            macd_rating=1\n",
    "        elif data_simple['signal_line'][index] > data_simple['MACD'][index] and data_simple['MACD'][index] > 0:\n",
    "            macd_rating=2\n",
    "        elif data_simple['MACD'][index] < 0 and 0 < data_simple['signal_line'][index]:\n",
    "            macd_rating=3\n",
    "        elif data_simple['MACD'][index] < data_simple['signal_line'][index] and data_simple['signal_line'][index]< 0:\n",
    "            macd_rating=4\n",
    "        elif data_simple['signal_line'][index] < data_simple['MACD'][index] and data_simple['MACD'][index] < 0:\n",
    "            macd_rating=5\n",
    "        elif data_simple['MACD'][index] > 0 and 0 > data_simple['signal_line'][index]:\n",
    "            macd_rating=6\n",
    "        return macd_rating,slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_rsi_values(stock, data_simple, n=14):\n",
    "#     ts = TechIndicators(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "#     try:\n",
    "#         data, meta_data = ts.get_rsi(symbol=stock_para, interval='daily') # interval = '1min'\n",
    "#         print('{}\\'s RSI is {}.'.format(stock_para,data['RSI'][-2]))\n",
    "#     except:\n",
    "#         return -1\n",
    "#     if(data.empty):\n",
    "#         return -1\n",
    "#     if(data['RSI'][-1]>70 or data['RSI'][-1]<30):\n",
    "#         ret_val = -1\n",
    "#     else:\n",
    "#         ret_val = 1\n",
    "#     return ret_val\n",
    "   \n",
    "    #def RSI(self, prices, n=14):\n",
    "    \n",
    "    rsi = 0\n",
    "    index = len(data_simple.index)-1\n",
    "    prices = data_simple['Close']\n",
    "    symbol = stock\n",
    "    #print(symbol)\n",
    "    \n",
    "    deltas = np.diff(prices)\n",
    "    #if index >360:\n",
    "    #    seed = deltas[index-360 : index-360 + n+1]\n",
    "    #else:\n",
    "    seed = deltas[:n+1]\n",
    "    up = seed[seed >= 0].sum()/n\n",
    "    down = -seed[seed < 0].sum()/n\n",
    "    rs = up/down\n",
    "    rsi = np.zeros_like(prices)\n",
    "    rsi[:n] = 100. - 100./(1.+rs)\n",
    "\n",
    "    for i in range(n+1, len(prices)):\n",
    "        delta = deltas[i-1]  # The diff is 1 shorter\n",
    "\n",
    "        if delta > 0:\n",
    "            upval = delta\n",
    "            downval = 0.\n",
    "        else:\n",
    "            upval = 0.\n",
    "            downval = -delta\n",
    "\n",
    "        up = (up*(n-1) + upval)/n\n",
    "        down = (down*(n-1) + downval)/n\n",
    "\n",
    "        rs = up/down\n",
    "        rsi[i] = 100. - 100./(1.+rs)\n",
    "        \n",
    "    if(rsi[-1] == False):\n",
    "        print('RSI computing error found.')\n",
    "        return -1\n",
    "    elif(rsi[-1]>70 or rsi[-1]<30):\n",
    "        #print('{}\\'s RSI is {}.'.format(symbol,rsi[-1]))\n",
    "        rsi_rating = -1\n",
    "    else:\n",
    "        rsi_rating = 1\n",
    "        #print('{}\\'s RSI is {}.'.format(symbol,rsi[-1]))\n",
    "\n",
    "    return rsi_rating\n",
    "\n",
    "\n",
    "# 3/5/2020 Charlie suggests this label was wrong. He recommends RSI>40 for 1, and others for -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global Declarations\n",
    "\n",
    "reversal = 3 #reversal amount set to 3 as default\n",
    "\n",
    "# (price range, box size)\n",
    "#function will provide box sizes according to traditional method\n",
    "box_ranges = [(.25,.0625),\n",
    "              (1,.125), \n",
    "              (5,.25),\n",
    "              (20,.5),\n",
    "              (100,1),\n",
    "              (200,2),\n",
    "              (500,4),\n",
    "              (1000,5),\n",
    "              (25000,50),\n",
    "              (sys.maxsize,500)]\n",
    "\n",
    "#to check and update box size according to current value of stock\n",
    "def updateBoxSize(price):\n",
    "    for i in range (len(box_ranges)):\n",
    "        if price < box_ranges[i][0]: #Zhen: Does it return multiple values?\n",
    "            return box_ranges[i][1] \n",
    "    return None\n",
    "\n",
    "\n",
    "#using alpha_vantage because quandl gives only data till March 2018\n",
    "\n",
    "#if current trend is x update x column appropriately or move to o column if needed\n",
    "def updateX(item, list1, list2, box_size, reversal, current_trend, numberofXBoxes, numberofOBoxes):\n",
    "    box_size = updateBoxSize(list1[-1])\n",
    "   # print(math.floor(item[\"High\"]))\n",
    "    if ( math.floor(item[\"High\"]) >= list1[-1]+box_size ):\n",
    "        list1[-1] = math.floor(item[\"High\"])\n",
    "    #   print(\"Updated the x value to:\"+str(list1[-1]))\n",
    "        numberofXBoxes += 1\n",
    "    elif ( math.ceil(item[\"Low\"]) <= list1[-1]-reversal*box_size):\n",
    "        list2.append(math.ceil(item[\"Low\"]))\n",
    "    #   print(\"Updated the o value to:\"+str(list2[-1]))\n",
    "        current_trend = 'o'\n",
    "        numberofOBoxes += 1\n",
    "    return current_trend\n",
    "\n",
    "#if current trend is o update o column appropriately or move to x column if needed\n",
    "def updateO(item, list1, list2, box_size, reversal, current_trend,  numberofXBoxes, numberofOBoxes):\n",
    "    box_size = updateBoxSize(list2[-1])\n",
    "    if ( math.ceil(item[\"Low\"]) <= list2[-1]-box_size ):\n",
    "        list2[-1] = math.ceil(item[\"Low\"])\n",
    "#        print(\"Updated the o value to:\"+str(list2[-1]))\n",
    "        numberofOBoxes += 1\n",
    "    elif ( math.floor(item[\"High\"]) >= list2[-1]+reversal*box_size):\n",
    "        list1.append(math.floor(item[\"High\"]))\n",
    " #       print(\"Updated the x value to:\"+str(list1[-1]))\n",
    "        current_trend = 'x'\n",
    "        numberofXBoxes += 1\n",
    "    return current_trend\n",
    "\n",
    "#create the point and figure from scratch\n",
    "\n",
    "def pointAndFigureCreate(box_size,current_trend, list1, list2, stockhilowdata, numberofXBoxes, numberofOBoxes):\n",
    "    #iterate over each date for the stock and create x or o columns\n",
    "    for index,row in stockhilowdata.iloc[0:].iterrows():\n",
    "        if current_trend == 'x':\n",
    "        #   print(\"The price is:\"+str(row[\"High\"]))\n",
    "            current_trend = updateX(row, list1, list2, box_size, reversal, current_trend, numberofXBoxes, numberofOBoxes)\n",
    "        elif current_trend=='o':\n",
    "            current_trend = updateO(row, list1, list2, box_size, reversal, current_trend, numberofXBoxes, numberofOBoxes)\n",
    "          #  print(\"The price is:\"+str(row[\"Low\"]))\n",
    "    return current_trend\n",
    "\n",
    "#check for a continous triple top pattern\n",
    "def continous_triple_top(current_trend, list1):\n",
    "    if(len(list1)<3):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'x':\n",
    "        if((list1[-1]> list1[-2]) and (list1[-2] == list1[-3])):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "        \n",
    "#check for a continous triple bottom pattern\n",
    "def continous_triple_bottom(current_trend, list2):\n",
    "    if(len(list2)<3):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'o':\n",
    "        if((list2[-1] < list2[-2]) and (list2[-2] == list2[-3])):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "#check for a continous double top pattern\n",
    "def continous_double_top(current_trend, list1):\n",
    "    if(len(list1)<2):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend=='x':\n",
    "        if(list1[-1]> list1[-2]):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "#check for a continous double bottom pattern\n",
    "def continous_double_bottom(current_trend, list2):\n",
    "    if(len(list2)<2):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'o':\n",
    "        if(list2[-1]< list2[-2]):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "def continous_quadruple_top(current_trend, list1):\n",
    "    if(len(list1)<4):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'x' and len(list1)>3:\n",
    "        if((list1[-1] > list1[-2]) and (list1[-2] == list1[-3] == list1[-4])):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "def continous_quadruple_bottom(current_trend, list2):\n",
    "    if(len(list2)<4):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'o' and len(list2)>3:\n",
    "        if((list2[-1] < list2[-2]) and (list2[-2] == list2[-3] == list2[-4])):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "import itertools\n",
    "def spread_triple_top(current_trend, list1):\n",
    "    ret_val = -1\n",
    "    if current_trend == 'x' and len(list1)>7:\n",
    "        iterprev = 0\n",
    "        resistance = 0\n",
    "        notstt = True\n",
    "        for iter in list1[-2:-7:1]:\n",
    "            if iterprev == iter:\n",
    "                resistance = iter\n",
    "                notstt = False\n",
    "            if resistance!=0 and iter > resistance:\n",
    "                notstt = True\n",
    "                break\n",
    "            iterprev = iter\n",
    "        if(notstt == False):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "def spread_triple_bottom(current_trend, list2):\n",
    "    ret_val = -1\n",
    "    if current_trend == 'o' and len(list2)>7:\n",
    "        iterprev = 0\n",
    "        support = 0\n",
    "        notstb = True\n",
    "        for iter in list2[-2:-7:1]:\n",
    "            if iterprev == iter:\n",
    "                support = iter\n",
    "                notstb = False\n",
    "            if support!=0 and iter<resistance:\n",
    "                notstb = True\n",
    "                break\n",
    "            iterprev = iter\n",
    "        if(notstb == False):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "def get_support_levels(list2):\n",
    "    if(len(list2)>=2):\n",
    "        return list2[-1],list2[-2]\n",
    "    elif (len(list2)==1):\n",
    "        return list2[-1],0\n",
    "    else:\n",
    "        return 0,0\n",
    "\n",
    "def get_resistance_levels(list1):\n",
    "    if(len(list1)>=2):\n",
    "        return list1[-1],list1[-2]\n",
    "    elif (len(list1)==1):\n",
    "        return list1[-1],0\n",
    "    else:\n",
    "        return 0,0\n",
    "    \n",
    "    \n",
    "def PnFMain(myData):\n",
    "    #list1 stores the highest value of each x column by index\n",
    "    #list2 stores the lowest value of each o column by index\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "\n",
    "    #current_trend stores the value of the most recent trend. we start off with x as default\n",
    "    current_trend = 'x'\n",
    "\n",
    "    numberofXBoxes = 1 # to get number of x boxes in all\n",
    "    numberofOBoxes = 0 # to get number of o boxes in all\n",
    "\n",
    "    #set box size according to price on day 1\n",
    "    box_size = updateBoxSize(myData[\"High\"].iloc[0])\n",
    "    #append price on day 1 to list1 as we stfart with x\n",
    "    list1.append(math.floor(myData[\"High\"].iloc[0]))\n",
    "    current_trend = pointAndFigureCreate(box_size, current_trend, list1, list2, myData, numberofXBoxes, numberofOBoxes)\n",
    "    ret_val_triple_top = continous_triple_top(current_trend,list1)\n",
    "    ret_val_triple_bottom = continous_triple_bottom(current_trend,list2)\n",
    "    ret_val_double_top = continous_double_top(current_trend,list1)\n",
    "    ret_val_double_bottom = continous_double_bottom(current_trend,list2)\n",
    "    ret_val_quadruple_top = continous_quadruple_top(current_trend,list1)\n",
    "    ret_val_quadruple_bottom = continous_quadruple_bottom(current_trend,list2)\n",
    "    ret_val_spread_triple_top = spread_triple_top(current_trend,list1)\n",
    "    ret_val_spread_triple_bottom = spread_triple_bottom(current_trend,list2)\n",
    "    \n",
    "    global support1\n",
    "    global support2\n",
    "    global resistance1\n",
    "    global resistance2\n",
    "    \n",
    "    support1,support2 = get_support_levels(list2)\n",
    "    resistance1,resistance2 = get_resistance_levels(list1)\n",
    "    \n",
    "    if ret_val_quadruple_top == 1:\n",
    "        return 'a'\n",
    "    elif ret_val_triple_top == 1:\n",
    "        return 'b'\n",
    "    elif ret_val_double_top == 1:\n",
    "        return 'c'\n",
    "    elif ret_val_quadruple_bottom == 1:\n",
    "        return 'd'\n",
    "    elif ret_val_triple_bottom == 1:\n",
    "        return 'e'\n",
    "    elif ret_val_double_bottom == 1:\n",
    "        return 'f'\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sector_etf_list=['XLF']\\nsector_sma_rating={'XLF':0}\\nsector_macd_rating={'XLF':0}\\nsector_macd_slope={'XLF':0}\\nsector_pnf_rating={'XLF':0}\\nsector_rsi_rating={'XLF':0}\\nsector_etf_to_names={'XLF':financial_list}\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_list=list()\n",
    "energy_list=list()\n",
    "industrial_list=list()\n",
    "comm_services_list=list()\n",
    "materials_list=list()\n",
    "health_list=list()\n",
    "consumer_list=list()\n",
    "technology_list=list()\n",
    "consumer_stap_list=list()\n",
    "\n",
    "sector_etf_list=['XLF','XLE','XLI','XLC','XLB','XLV','XLY','XLK','XLP']\n",
    "sector_sma_rating={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_macd_rating={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_macd_slope={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_pnf_rating={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_rsi_rating={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_etf_to_names={'XLF':financial_list,'XLE':energy_list,'XLI':industrial_list,'XLC':comm_services_list,'XLB':materials_list,'XLV':health_list,'XLY':consumer_list,'XLK':technology_list,'XLP':consumer_stap_list}\n",
    "\n",
    "\n",
    "\"\"\"sector_etf_list=['XLF']\n",
    "sector_sma_rating={'XLF':0}\n",
    "sector_macd_rating={'XLF':0}\n",
    "sector_macd_slope={'XLF':0}\n",
    "sector_pnf_rating={'XLF':0}\n",
    "sector_rsi_rating={'XLF':0}\n",
    "sector_etf_to_names={'XLF':financial_list}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code uses datahub.io to collect S&P500 members' symbols.\n",
    "#\n",
    "#package = Package('https://datahub.io/core/s-and-p-500-companies/datapackage.json')\n",
    "# for resource in package.resources:\n",
    "#     if resource.descriptor['datahub']['type'] == 'derived/csv':\n",
    "#         my_list=resource.read()\n",
    "# df = pd.DataFrame(my_list, columns=['Symbol','Name','Sector'])\n",
    "\n",
    "\n",
    "\n",
    "# This code uses wikipedia.org to collect S&P members' symbols\n",
    "\n",
    "import pandas as pd\n",
    "table = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies', header = 0)\n",
    "df1 = table[0]\n",
    "\n",
    "df = df1[['Symbol', 'Security', 'GICS Sector']]\n",
    "\n",
    "df = df.rename(columns = {\"GICS Sector\":'Sector'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df['Sector'][i]=='Industrials':\n",
    "        industrial_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Health Care':\n",
    "        health_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Energy':\n",
    "        energy_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Financials':\n",
    "        financial_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Information Technology':\n",
    "        technology_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Consumer Discretionary':\n",
    "        consumer_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Materials':\n",
    "        materials_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Communication Services':\n",
    "        comm_services_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Consumer Staples':\n",
    "        consumer_stap_list.append(df['Symbol'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef data_test():\\n    \"\"\"Check the integrety of data.\"\"\"\\n    from pandas.tseries.offsets import BDay\\n\\n    today = datetime.today()\\n    LastBday = today - BDay(1)\\n\\n    print(\\'The last business date is {}.\\'.format(LastBday.date()))\\n    testData, symbol = get_all_data(\\'SPY\\') \\n    #print(type(testData.index[-1]))\\n    data_date = datetime.strptime(testData.index[-1], \"%Y-%m-%d %H:%M:%S\")\\n    #print(data_date.date())\\n    print(\\'The last date in data is {}.\\'.format(data_date.date())) #format(data_date) #.date())\\n\\n    if data_date.date() != LastBday.date():\\n        print(\\'\\n ###################################################################### \\n #  The last business day\\'s data is incorrect. Check the data source. # \\n ######################################################################\\')\\n        raise SystemExit\\n    else:\\n        print(\\'The last business day\\'s data is correct. You can proceed.\\')\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def data_test():\n",
    "    \"\"\"Check the integrety of data.\"\"\"\n",
    "    from pandas.tseries.offsets import BDay\n",
    "\n",
    "    today = datetime.today()\n",
    "    LastBday = today - BDay(1)\n",
    "\n",
    "    print('The last business date is {}.'.format(LastBday.date()))\n",
    "    testData, symbol = get_all_data('SPY') \n",
    "    #print(type(testData.index[-1]))\n",
    "    data_date = datetime.strptime(testData.index[-1], \"%Y-%m-%d %H:%M:%S\")\n",
    "    #print(data_date.date())\n",
    "    print('The last date in data is {}.'.format(data_date.date())) #format(data_date) #.date())\n",
    "\n",
    "    if data_date.date() != LastBday.date():\n",
    "        print('\\n ###################################################################### \\n \\\n",
    "#  The last business day\\'s data is incorrect. Check the data source. # \\n\\\n",
    " ######################################################################')\n",
    "        raise SystemExit\n",
    "    else:\n",
    "        print('The last business day\\'s data is correct. You can proceed.')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_test()'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data_test()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLF:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:05<00:42,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLE:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:06<00:28,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLI:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:09<00:23,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLC:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:10<00:15,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLB:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:12<00:10,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLV:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:15<00:07,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLY:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:17<00:05,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLK:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:21<00:02,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLP:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:22<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''Get data for applying ratings.'''\n",
    "df_rated_now = pd.DataFrame()\n",
    "\n",
    "for sector in tqdm(sector_etf_list):\n",
    "    print(sector+':', end = '')\n",
    "    for i in range(0,len(sector_etf_to_names[sector])):        \n",
    "        myData, company_name = get_all_data(sector_etf_to_names[sector][i])            \n",
    "        if(not myData.empty):\n",
    "            macd_rating,slope = MACD_rating(myData)\n",
    "            df_rated_now = df_rated_now.append({'Stock Symbol':sector_etf_to_names[sector][i], \\\n",
    "                                               'Company Name': company_name, \\\n",
    "                                               'SMA':SMA_rating(myData), \\\n",
    "                                               'MACD':macd_rating,'MACD Slope':slope, 'PnF':PnFMain(myData), \\\n",
    "                                               #'RSI':daily_rsi_values(sector_etf_to_names[sector][i]), \\\n",
    "                                                'RSI':daily_rsi_values(sector_etf_to_names[sector][i], myData), \\\n",
    "                                               'Support1':support1, 'Support2':support2,'Resistance1':resistance1, 'Resistance2':resistance2 }, \\\n",
    "                                              ignore_index=True)\n",
    "        else:\n",
    "            print('Data for stock is not present in the API')\n",
    "    #print(df_rated_now)\n",
    "\n",
    "print('Done')\n",
    "\n",
    "\n",
    "# df_rated_now[df_rated_now['Stock Symbol']=='FBHS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rated_now.to_csv('Rated_Stocks_All.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define contral groupo\n",
    "# Randomly choose 20 stocks from the full list of stocks\n",
    "\n",
    "df_control = df_rated_now.sample(n=40)\n",
    "\n",
    "df_control = df_control.rename(columns={\"Stock Symbol\":\"Symbol\"})\n",
    "\n",
    "# df_control.to_csv(r'C:\\Users\\User\\Box\\WOOatUB\\YashaAbhinavRohit\\Stock_List_Control.csv')\n",
    "\n",
    "# df_control.to_csv(r'C:\\Users\\User\\Box\\WOOatUB\\YashaAbhinavRohit\\ContractsData\\\\'+ datetime.today().strftime('%Y-%m-%d')+'_control''.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD Slope</th>\n",
       "      <th>PnF</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Resistance1</th>\n",
       "      <th>Resistance2</th>\n",
       "      <th>SMA</th>\n",
       "      <th>Stock Symbol</th>\n",
       "      <th>Support1</th>\n",
       "      <th>Support2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aflac Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AFL</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allstate Corp</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>120.0</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Express Co</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AXP</td>\n",
       "      <td>139.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American International Group Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>AIG</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ameriprise Financial Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c</td>\n",
       "      <td>1.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AMP</td>\n",
       "      <td>300.0</td>\n",
       "      <td>257.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Company Name  MACD  MACD Slope  PnF  RSI  Resistance1  \\\n",
       "0                         Aflac Inc   1.0         1.0    c -1.0         68.0   \n",
       "1                     Allstate Corp   4.0         1.0    c  1.0        129.0   \n",
       "2               American Express Co   6.0         1.0  NaN  1.0        146.0   \n",
       "3  American International Group Inc   1.0         1.0    c -1.0         58.0   \n",
       "4          Ameriprise Financial Inc   1.0         1.0    c  1.0        319.0   \n",
       "\n",
       "   Resistance2  SMA Stock Symbol  Support1  Support2  \n",
       "0         60.0  1.0          AFL      57.0      57.0  \n",
       "1        127.0  1.0          ALL     120.0     117.0  \n",
       "2        149.0  4.0          AXP     139.0     133.0  \n",
       "3         51.0  6.0          AIG      48.0      48.0  \n",
       "4        317.0  1.0          AMP     300.0     257.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from alpha_vantage.timeseries import TimeSeries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "#import quandl\n",
    "import sys\n",
    "import math\n",
    "#from alpha_vantage.techindicators import TechIndicators\n",
    "#from datapackage import Package\n",
    "import urllib.request, json\n",
    "#from pymemcache.client import base\n",
    "\n",
    "Location = r'Rated_Stocks_All.csv'\n",
    "df_rated_now = pd.read_csv(Location)\n",
    "df_rated_now.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_final_list():\n",
    "    final_list = []\n",
    "    pnf_list = ['a','b','c']\n",
    "    for index,row in df_rated_now.iloc[0:].iterrows():\n",
    "        if row['MACD'] == 1 and row['MACD Slope'] == 1 and row['SMA'] == 1 and row['PnF'] in pnf_list and row['RSI'] == 1:\n",
    "            row_data = {'Symbol':row['Stock Symbol'] , 'Company Name':row['Company Name'], 'Score':row['PnF'], 'Support1':row['Support1'],'Support2':row['Support2'],'Resistance1':row['Resistance1'],'Resistance2':row['Resistance2']}\n",
    "            final_list.append(row_data)\n",
    "    final_df = pd.DataFrame(final_list)\n",
    "    if not final_df.empty:\n",
    "        final_df['SymbolKey'] = final_df['Symbol']\n",
    "        final_df.set_index('SymbolKey', inplace = True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_close_price(stock_list):\n",
    "    '''For Point and Figure rating'''\n",
    "    close_price = list()\n",
    "    for row in stock_list.iterrows():\n",
    "        symbol = row[1]['Symbol']\n",
    "        #print(\"Symbol is:\", symbol)\n",
    "            #symbol = symbol_para\n",
    "        start_date = '2010-01-01' #ts = TimeSeries(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "        try:\n",
    "            pricedata_dataframe = norgatedata.price_timeseries(\n",
    "                    symbol,\n",
    "                    stock_price_adjustment_setting = priceadjust,\n",
    "                    padding_setting = padding_setting,\n",
    "                    start_date = start_date,\n",
    "                    format=timeseriesformat)\n",
    "            close_price.append(pricedata_dataframe['Close'].iloc[-1])\n",
    "        except:\n",
    "            close_price.append(-1)\n",
    "    stock_list['Close Price']=close_price\n",
    "    return stock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_earnings_date(symbol):\n",
    "    # Use Yahoo Finance Earnings Calendar https://github.com/wenboyu2/yahoo-earnings-calendar\n",
    "    from datetime import datetime\n",
    "    from yahoo_earnings_calendar import YahooEarningsCalendar\n",
    "    my_custom_delay_s = 0.5\n",
    "    #try:\n",
    "    yec = YahooEarningsCalendar(my_custom_delay_s)# Returns the next earnings date of BOX in Unix timestamp\n",
    "    ts = yec.get_next_earnings_date(symbol)\n",
    "    return datetime.fromtimestamp(ts)\n",
    "    #except:\n",
    "        #print(symbol)\n",
    "    #    print('Situation: ' + symbol + 'Invalid Symbol or Unavailable Earnings Date')\n",
    "        #return datetime.fromtimestamp(ts)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 1, 30, 16, 0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_earnings_date('GOOGL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_five_global = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime  \n",
    "from datetime import timedelta\n",
    "import logging\n",
    "\n",
    "import config as cf\n",
    "\n",
    "\n",
    "# Following code makes relevant tokens necessary to conduct TD ameritrade activities on behalf of Zhen Liu's personal account\n",
    "# Note refresh token is valid for 90 days. It is used to generate auth token which is only valid for 30 mins\n",
    "def get_auth_token():\n",
    "    auth_params = {'grant_type':'refresh_token', 'refresh_token':cf.refresh_token, 'client_id': cf.client_id}\n",
    "    auth_api_url = 'https://api.tdameritrade.com/v1/oauth2/token'\n",
    "    headers = {'Content-Type': \"application/x-www-form-urlencoded\"}\n",
    "    data =  requests.post(auth_api_url, headers = headers, data=auth_params).json()\n",
    "    #print(data)\n",
    "    result = \"Bearer \"+ data['access_token']\n",
    "\n",
    "    return result\n",
    "\n",
    "# Following code will get the option chain data using the authorized token\n",
    "# Parameters: call_or_put: 'CALL'/'PUT'; symbol: string with stock symbol from passed in stock list\n",
    "def get_raw_option_data(call_or_put, symbol):\n",
    "    url = 'https://api.tdameritrade.com/v1/marketdata/chains'\n",
    "    strike_count = '100' #need to figure out how to get ALL or just use an arbitraliy huge num\n",
    "    strategy = 'SINGLE'\n",
    "    authorization_header = {'Authorization': get_auth_token()}\n",
    "    pay = {'symbol':symbol,'strikeCount':strike_count , 'strategy':strategy}\n",
    "    if call_or_put == \"CALL\":\n",
    "        return [requests.get(url, params = pay, headers = authorization_header).json()['callExpDateMap'], \n",
    "                requests.get(url, params = pay, headers = authorization_header).json()['underlyingPrice']]\n",
    "    elif call_or_put == \"PUT\":\n",
    "        return [requests.get(url, params = pay, headers = authorization_header).json()['putExpDateMap'], requests.get(url, params = pay, headers = authorization_header).json()['underlyingPrice']]\n",
    "\n",
    "\n",
    "\n",
    "# Following code does the filtering of the options data based on our chosen parameters\n",
    "def processing(symbol, Option_Data, supp1,supp2, params, call_or_put):\n",
    "    data = Option_Data[symbol]\n",
    "    agg_data = {}\n",
    "    date_keys = []\n",
    "    for (k,v) in data[0].items():\n",
    "        date_keys.append([k,list(v.keys())])\n",
    "        agg_data[k] = v\n",
    "        \n",
    "    #If there is no data regarding some symbol in API then just return an empty dataframe\n",
    "    if not date_keys:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    target_list = []\n",
    "    stock_price = data[1]\n",
    "    \n",
    "    if call_or_put == \"CALL\":\n",
    "        for i in range(0,len(date_keys)):\n",
    "            for j in range(0, len(date_keys[i][1])):\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] < params['days_min'] or agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] > params['days_max']: # Days to Expiration Requirement!\n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] < params['bid_min']: # Min/Max Bid requirement!\n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['totalVolume'] < params['min_vol']: # Min/Max Volume Requirement!\n",
    "                    continue\n",
    "                if (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price) / stock_price < params['%OTM_lim']: # Percent OTM Requirement!\n",
    "                    continue\n",
    "                if 1 - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'] < params['prob_OTM_lim']: # Prob OTM Requirement!\n",
    "                    continue\n",
    "                support = 0\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']<supp1 and agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']>supp2:\n",
    "                    support = 1\n",
    "                # construct a dictionary object characteristics we want and append to list\n",
    "                target = {'stock': symbol,\n",
    "                         'contract': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['symbol'],\n",
    "                         'strike_price':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'],\n",
    "                         'stock_price':stock_price,\n",
    "                         'days_to_exp':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'],\n",
    "                         'bid': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'],\n",
    "                         'ask': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['ask'],\n",
    "                         'last': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['last'],\n",
    "                         'prob_OTM': 1 - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'],\n",
    "                         '% OTM': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price) / stock_price,\n",
    "                         'cov_ret': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['mark']-((stock_price - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'])/stock_price)*(365/agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration']),\n",
    "                         'max_cov_ret': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['mark']+((agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price)/stock_price)*(365/agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration']),\n",
    "                         'prob_touch': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta']*2,\n",
    "                         'annual_return': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['ask'] * 365 * 100)/((agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']) * (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'])),\n",
    "                         'btwn_supports':support}\n",
    "                target_list.append(target)\n",
    "    elif call_or_put == \"PUT\":\n",
    "        for i in range(0,len(date_keys)):\n",
    "            for j in range(0, len(date_keys[i][1])):\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] < params['days_min'] or \\\n",
    "                agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] > params['days_max']: # Days to Expiration Requirement!\n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] < params['bid_min']: # Min/Max Bid requirement!\n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['totalVolume'] < params['min_vol']: # Min/Max Volume Requirement!\n",
    "                    continue\n",
    "                if (stock_price - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']) / \\\n",
    "                stock_price < params['%OTM_lim']: \n",
    "                    # Percent OTM Requirement!\n",
    "                    continue\n",
    "                prob_otm = 1 + float(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'])\n",
    "                #print(\"The prob of OTM is\", round(prob_otm, 2))\n",
    "                #print(\"The otm limit is\", params['prob_OTM_lim'])\n",
    "                if prob_otm < params['prob_OTM_lim']: # Prob OTM Requirement!      + or -???\n",
    "                    #print(\"The prob of OTM\", round(prob_otm, 2))\n",
    "                    continue\n",
    "                if (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] - \\\n",
    "                          max(0, (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - \\\n",
    "                            stock_price)))/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']- \\\n",
    "                                           agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid']) * 365 * 100/\\\n",
    "                           agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] < \\\n",
    "                            params['annual_ptnl_ret_lim']: # Covered return Requirement! \n",
    "                    continue\n",
    "                if float(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'])*(-2) > \\\n",
    "                params['prob_touch_lim']: # Probability of touching parameter      + or - ???\n",
    "                    continue\n",
    "                support = 0\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']<supp1 and agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']>supp2:\n",
    "                    support = 1\n",
    "#Commented code checks for 24% annual return. If required in future\n",
    "#                 value = (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid']*365*100)/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']*agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'])\n",
    "#                 if value<15:\n",
    "#                     continue\n",
    "    \n",
    "                # Construct a dictionary object characteristics we want and append to list\n",
    "                target = {'stock':symbol,\n",
    "                         'contract':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['symbol'],\n",
    "                         'strike_price':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'],\n",
    "                         'stock_price':stock_price,\n",
    "                         'days_to_exp':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'],\n",
    "                         'bid': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'],\n",
    "                         'ask': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['ask'],\n",
    "                         'last': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['last'],\n",
    "                         'prob_OTM': 1 + float(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta']), # + or - ???\n",
    "                         '% OTM': 1-agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']/stock_price,\n",
    "                         'ptnl_ret': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] - \\\n",
    "                          max(0, (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - \\\n",
    "                            stock_price)))/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']- \\\n",
    "                                           agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid']),\n",
    "                         'annual_ptnl_ret': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] - \\\n",
    "                          max(0, (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - \\\n",
    "                            stock_price)))/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']- \\\n",
    "                                           agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid']) * 365 * 100/\\\n",
    "                           agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'],\n",
    "\n",
    "                         'prob_touch': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta']*(-2),\n",
    "                         'btwn_supports': support}# + or - ???\n",
    "                \n",
    "#                 print(\"The value of accepted delta\",target['prob_OTM'])\n",
    "                target_list.append(target)\n",
    "    df = pd.DataFrame(target_list)\n",
    "    if(df.empty):\n",
    "        print('Got empty')\n",
    "        return df\n",
    "    df = df.set_index('contract', drop = True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Following function returns price data for a stock which can be used to construct a P&F chart\n",
    "def return_candle_data(symbol):\n",
    "    candle_url = 'https://api.tdameritrade.com/v1/marketdata/'+symbol+'/pricehistory'\n",
    "    candle_header = {'Authorization': get_auth_token()}\n",
    "    # Vary the properties below depending on how often you want the data\n",
    "    # Ideally, we want to set up a web socket to continuously stream this data?\n",
    "    period_type = 'day'\n",
    "    period = 2\n",
    "    freq_type = 'minute'\n",
    "    freq = 1\n",
    "    candle_payload = {'periodType': period_type, 'period': period, 'frequencyType': freq_type, 'frequency': freq}\n",
    "    raw_candle_data = requests.get(candle_url, params = candle_payload, headers = candle_header).json()\n",
    "    df = pd.DataFrame(raw_candle_data['candles'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def report(stock_list, Option_Data, put_parameters):\n",
    "    # Select by WOO ratings and earnings dates criteria\n",
    "    \n",
    "    df_top_five_all =  pd.DataFrame()\n",
    "    \n",
    "    d0 = date.today()\n",
    "    \n",
    "    for row in tqdm(stock_list.iterrows()):\n",
    "        item = row[1]['Symbol']\n",
    "        supp1 = row[1]['Support1']\n",
    "        supp2 = row[1]['Support2']\n",
    "        name = row[1]['Company Name']\n",
    "        print(item, end=\" \")\n",
    "        df = processing(item, Option_Data, supp1,supp2, put_parameters, \"PUT\")\n",
    "        if(not df.empty):\n",
    "            df_top_five = df.sort_values(by=['annual_ptnl_ret'], ascending=False)\n",
    "            df_top_five = df_top_five.head(5)\n",
    "            df_top_five['company name'] = name\n",
    "            if df_top_five_all.empty:\n",
    "                df_top_five_all = df_top_five\n",
    "            else:\n",
    "                df_top_five_all = df_top_five_all.append(df_top_five)\n",
    "        #time.sleep(5)\n",
    "                \n",
    "    if(not df_top_five_all.empty):\n",
    "        df_top_five_all = df_top_five_all.sort_values(by=['btwn_supports','stock','annual_ptnl_ret'], ascending=[False,True,False])\n",
    "        \n",
    "        df_top_five_all['Days to Earnings'] = '!' # In case earnings date data is not avaialbe, avoid reporting the contracts.\n",
    "        \n",
    "        df_top_five_all['Risk level'] = put_parameters['label']\n",
    "        \n",
    "        for index, row in df_top_five_all.iterrows():\n",
    "            \n",
    "            try:\n",
    "                ed = next_earnings_date(row['stock']).date()\n",
    "                delta = ed - d0 #compute dates from today to earnings date\n",
    "                #print(delta.days)\n",
    "                print('The next earnings date of {} is {}.'.format(row['stock'],ed))\n",
    "           \n",
    "                #if delta.days>0: # Yahoo may report earning dates that just passed.\n",
    "                d_days = delta.days - row['days_to_exp']                \n",
    "\n",
    "                if (d_days <= 0):\n",
    "                    df_top_five_all = df_top_five_all.drop(index, axis=0)\n",
    "                else:\n",
    "                    df_top_five_all.at[index, 'Days to Earnings']= delta.days\n",
    "            except:\n",
    "                print('Error happens in finding the next earnings data.')\n",
    "                df_top_five_all = df_top_five_all.drop(index, axis=0)\n",
    "                pass\n",
    "\n",
    "    else:\n",
    "        print(\"No contracts available in the {} criteria.\".format(put_parameters['label']))\n",
    "    \n",
    "    return df_top_five_all    \n",
    "               \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final stock list is done.\n"
     ]
    }
   ],
   "source": [
    "stock_list = get_final_list() # Need to populate this array with stock list we derive from technical indicators\n",
    "#earnings_df = earnings_dates()\n",
    "#print('Earnings List:',earnings_df)\n",
    "#print('Stock List Before:', stock_list)\n",
    "\n",
    "# stock_list.to_csv(r'C:\\Users\\User\\Box\\WOOatUB\\YashaAbhinavRohit\\Stock_List.csv')\n",
    "\n",
    "# stock_list.to_csv(r'C:\\Users\\User\\Box\\WOOatUB\\YashaAbhinavRohit\\ContractsData\\\\'+ datetime.today().strftime('%Y-%m-%d')+'.csv')\n",
    "\n",
    "if stock_list.empty == 0:\n",
    "    stock_list.sort_values(by=['Score'], ascending = False)    \n",
    "    stock_list = get_close_price(stock_list)\n",
    "    print('Final stock list is done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity\n",
    "stock_list.to_csv(\"norgate_stock_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:00, 262.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMP Got empty\n",
      "AJG WRB Got empty\n",
      "CBOE Got empty\n",
      "NDAQ COP MRO MPC OXY FTV Got empty\n",
      "IEX Got empty\n",
      "PWR SNA Got empty\n",
      "GWW APD MCK GPC Got empty\n",
      "MSI PTC Got empty\n",
      "CAG Got empty\n",
      "MNST The next earnings date of GWW is 2023-02-02.\n",
      "The next earnings date of MCK is 2023-01-31.\n",
      "The next earnings date of MNST is 2022-11-03.\n",
      "The next earnings date of MNST is 2022-11-03.\n",
      "The next earnings date of MSI is 2022-11-03.\n",
      "The next earnings date of PWR is 2022-11-03.\n",
      "The next earnings date of PWR is 2022-11-03.\n",
      "The next earnings date of AJG is 2023-01-25.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of MCK is 2023-01-31.\n",
      "The next earnings date of MCK is 2023-01-31.\n",
      "The next earnings date of MCK is 2023-01-31.\n",
      "The next earnings date of MCK is 2023-01-31.\n",
      "The next earnings date of MNST is 2022-11-03.\n",
      "The next earnings date of MNST is 2022-11-03.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MRO is 2022-11-03.\n",
      "The next earnings date of MRO is 2022-11-03.\n",
      "The next earnings date of MRO is 2022-11-03.\n",
      "The next earnings date of MRO is 2022-11-03.\n",
      "The next earnings date of MRO is 2022-11-03.\n",
      "The next earnings date of MSI is 2022-11-03.\n",
      "The next earnings date of NDAQ is 2023-01-24.\n",
      "The next earnings date of NDAQ is 2023-01-24.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:00, 375.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next earnings date of OXY is 2022-11-08.\n",
      "AMP Got empty\n",
      "AJG Got empty\n",
      "WRB Got empty\n",
      "CBOE Got empty\n",
      "NDAQ COP MRO MPC OXY FTV Got empty\n",
      "IEX Got empty\n",
      "PWR Got empty\n",
      "SNA Got empty\n",
      "GWW Got empty\n",
      "APD MCK Got empty\n",
      "GPC Got empty\n",
      "MSI PTC Got empty\n",
      "CAG Got empty\n",
      "MNST Got empty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of MSI is 2022-11-03.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MRO is 2022-11-03.\n",
      "The next earnings date of NDAQ is 2023-01-24.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:00, 677.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next earnings date of OXY is 2022-11-08.\n",
      "AMP Got empty\n",
      "AJG Got empty\n",
      "WRB Got empty\n",
      "CBOE Got empty\n",
      "NDAQ Got empty\n",
      "COP MRO Got empty\n",
      "MPC OXY FTV Got empty\n",
      "IEX Got empty\n",
      "PWR Got empty\n",
      "SNA Got empty\n",
      "GWW Got empty\n",
      "APD MCK Got empty\n",
      "GPC Got empty\n",
      "MSI Got empty\n",
      "PTC Got empty\n",
      "CAG Got empty\n",
      "MNST Got empty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of OXY is 2022-11-08.\n"
     ]
    }
   ],
   "source": [
    "# #df['EA'][0]\n",
    "# Date_Keys = []\n",
    "# Agg_Data = {}\n",
    "\n",
    "# for (k,v) in df['ULTA'][0].items():\n",
    "#     date_keys.append([k,list(v.keys())])\n",
    "#     agg_data[k] = v\n",
    "    \n",
    "    \n",
    "# Set selection parameters\n",
    "safe_put_parameters = {'days_min': 1, 'days_max': 60, 'bid_min':0.25, 'bid_max': 10000000, 'min_vol': 5, \\\n",
    "                       'max_vol': 1000000000, '%OTM_lim': 0.0, 'prob_OTM_lim': 0.95, 'annual_ptnl_ret_lim': 0.01, \\\n",
    "                       'prob_touch_lim': 0.9, 'label': 'safe'}\n",
    "mod_put_parameters = {'days_min': 1, 'days_max': 60, 'bid_min':0.25, 'bid_max': 10000000, 'min_vol': 5, \\\n",
    "                      'max_vol': 1000000000, '%OTM_lim': 0.0, 'prob_OTM_lim': 0.90, 'annual_ptnl_ret_lim': 0.01, \\\n",
    "                      'prob_touch_lim': 0.9, 'label': 'moderate'}\n",
    "risky_put_parameters = {'days_min': 1, 'days_max': 60, 'bid_min':0.25, 'bid_max': 10000000, 'min_vol': 5, \\\n",
    "                        'max_vol': 1000000000, '%OTM_lim': 0.0, 'prob_OTM_lim': 0.80, 'annual_ptnl_ret_lim': 0.01, \\\n",
    "                        'prob_touch_lim': 0.9, 'label': 'risky'}\n",
    "\n",
    "# Collect option data\n",
    "\n",
    "data = {}\n",
    "\n",
    "for row in stock_list.iterrows():\n",
    "    item = row[1]['Symbol'] \n",
    "    #print(item)\n",
    "    data_entry = get_raw_option_data('PUT', item)\n",
    "    data.update({item: data_entry})\n",
    "    time.sleep(2)\n",
    "    \n",
    "Option_Data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Generating recommendations\n",
    "df_risky = report(stock_list, Option_Data, risky_put_parameters)\n",
    "\n",
    "df_mod = report(stock_list, Option_Data, mod_put_parameters)\n",
    "\n",
    "df_safe = report(stock_list, Option_Data, safe_put_parameters)\n",
    "\n",
    "\n",
    "Frames = [df_risky, df_mod, df_safe]\n",
    "\n",
    "# Collect option data\n",
    "\n",
    "# data = {}\n",
    "\n",
    "# for row in df_control.iterrows():\n",
    "#     item = row[1]['Symbol'] \n",
    "#     #print(item)\n",
    "#     data_entry = get_raw_option_data('PUT', item)\n",
    "#     data.update({item: data_entry})\n",
    "#     time.sleep(2)\n",
    "    \n",
    "# Option_Data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Generating control group\n",
    "\n",
    "# df_risky = report(df_control, Option_Data, risky_put_parameters)\n",
    "\n",
    "# df_mod = report(df_control, Option_Data, mod_put_parameters)\n",
    "\n",
    "# df_safe = report(df_control, Option_Data, safe_put_parameters)\n",
    "\n",
    "\n",
    "# Frames_Control = [df_risky, df_mod, df_safe]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_result(frames):\n",
    "    '''Generate final results'''\n",
    "    df = pd.concat(frames)\n",
    "    df.reset_index(inplace = True)\n",
    "\n",
    "    for i in df.index:\n",
    "        '''Managing the duplcation of contracts at different risky levels'''\n",
    "        #print(df.iloc[i]['Risk level']) #.values[0] == 'risky')\n",
    "        if df.loc[i,'Risk level'] in  ['moderate', 'Moderate']:\n",
    "            try:\n",
    "                index_names = df[(df['Risk level'].isin(['Risky', 'risky'])) & \\\n",
    "                                 (df['contract'] == df.loc[i,'contract'])].index\n",
    "                df.drop(index_names, inplace = True)\n",
    "\n",
    "            except:\n",
    "                print('Something is wrong when removing moderate contracts from risky ones.')\n",
    "\n",
    "    for i in df.index:\n",
    "        if df.loc[i,'Risk level'] in ['Safe', 'safe']:\n",
    "            try:\n",
    "                index_names = df[(df['Risk level'].isin(['moderate', 'Moderate']))\\\n",
    "                                 & (df['contract'] == df.loc[i,'contract'])].index\n",
    "                df.drop(index_names, inplace = True)\n",
    "            except:\n",
    "                print('Something is wrong when removing safe contracts from moderate ones.')\n",
    "\n",
    "    df['Date of recommendation'] = datetime.today().strftime('%Y-%m-%d') # add the date of recommendation column\n",
    "\n",
    "    df.reset_index(inplace = True)\n",
    "\n",
    "    #df.set_index('contract', inplace = True)\n",
    "\n",
    "    if len(df) == 0:\n",
    "        no_rec_dict = {'index': '0000',\n",
    "                       'contract': ['No Recommendations'],\n",
    "                       'stock': ['No Recommendations'],\n",
    "                       'strike_price':[np.nan],\n",
    "                       'stock_price':[np.nan],\n",
    "                       'days_to_exp':[np.nan],\n",
    "                       'bid': [np.nan],\n",
    "                       'ask': [np.nan],\n",
    "                       'last': [np.nan],\n",
    "                       'prob_OTM': [np.nan],\n",
    "                       '% OTM': [np.nan],\n",
    "                       'ptnl_ret': [np.nan],\n",
    "                       'annual_ptnl_ret': [np.nan],\n",
    "                       'prob_touch': [np.nan],\n",
    "                       'btwn_supports': [np.nan],\n",
    "                       'company name': [''],\n",
    "                       'Days to Earnings': [np.nan],\n",
    "                       'Risk level': [''], \n",
    "                       'Date of recommendation': [datetime.today().strftime('%Y-%m-%d')]               \n",
    "                         }\n",
    "        df_no_rec = pd.DataFrame.from_dict(no_rec_dict)\n",
    "        #print(df)\n",
    "        df = df.append(df_no_rec)\n",
    "    return df\n",
    "\n",
    "result_df = final_result(Frames)\n",
    "\n",
    "# result_df.to_csv(r'C:\\Users\\User\\Box\\WOOatUB\\YashaAbhinavRohit\\ContractsData\\'' + datetime.today().strftime('%Y-%m-%d')+'_final_list.csv')\n",
    "\n",
    "# result_df_control = final_result(Frames_Control)\n",
    "# result_df_control.to_csv(r'C:\\Users\\User\\Box\\WOOatUB\\YashaAbhinavRohit\\ContractsData\\'' + datetime.today().strftime('%Y-%m-%d')+'_final_list_control.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity\n",
    "result_df.to_csv(\"norgate_result.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import gspread\n",
    "# from oauth2client.service_account import ServiceAccountCredentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Update to Google Sheet \n",
    "\n",
    "# # Mert's Google Sheet\n",
    "# scope = [\"https://spreadsheets.google.com/feeds\",'https://www.googleapis.com/auth/spreadsheets',\"https://www.googleapis.com/auth/drive.file\",\"https://www.googleapis.com/auth/drive\"]\n",
    "# creds = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json', scope)\n",
    "# client = gspread.authorize(creds)\n",
    "\n",
    "# print(\"Started fetching data\")\n",
    "# sheet =  client.open(\"Algo_Recommendations\").worksheet(\"All_The_Recommendations\")\n",
    "# print(\"Data fetching completed\")\n",
    "\n",
    "# for i in result_df.index:\n",
    "#     values = [ str(i), str(result_df.loc[i,'contract']), str(result_df.loc[i,'% OTM']), \\\n",
    "#               str(result_df.loc[i,'annual_ptnl_ret']), str(result_df.loc[i,'ask']), str(result_df.loc[i,'bid']), \\\n",
    "#               str(result_df.loc[i,'btwn_supports']), str(result_df.loc[i,'days_to_exp']), str(result_df.loc[i,'last']), \n",
    "#               str(result_df.loc[i,'prob_OTM']), str(result_df.loc[i,'prob_touch']), str(result_df.loc[i,'ptnl_ret']), \n",
    "#               str(result_df.loc[i,'stock']), str(result_df.loc[i,'stock_price']), str(result_df.loc[i,'strike_price']), str(result_df.loc[i,'company name']), \n",
    "#               str(result_df.loc[i,'Days to Earnings']), str(result_df.loc[i,'Risk level']), str(result_df.loc[i,'Date of recommendation'])]\n",
    "#     #print(values)\n",
    "#     sheet.append_row(values) # we cannot send more than 100 contracts per 5 minutes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Mert's Google Server\n",
    "\n",
    "# #df=pd.read_csv('2020-08-11_final_list.csv')\n",
    "# new_df=result_df.rename(columns={'% OTM':'percentage_OTM', 'company name':'company_name', \n",
    "#                           'Days to Earnings': 'days_to_earnings', 'Risk level': 'risk_level', \n",
    "#                           'Date of recommendation': 'date_of_recommendation'})\n",
    "# print(new_df)\n",
    "\n",
    "\n",
    "# def convertDateToTDAmeritradeDate(date):\n",
    "#     month = date[0] + date[1];\n",
    "#     day = date[2] + date[3];\n",
    "#     year = \"20\" + date[4] + date[5];\n",
    "\n",
    "#     return year + \"-\" + month + \"-\" + day + \" 16:00:00\";\n",
    "\n",
    "\n",
    "# def getContractData(contract):\n",
    "#     name_and_rest = contract.split(\"_\");\n",
    "#     date_and_strike = name_and_rest[1].split(\"P\");\n",
    "#     date = convertDateToTDAmeritradeDate(date_and_strike[0]);\n",
    "#     #print(date)\n",
    "#     return date;\n",
    "\n",
    "# #datetime_str = '08/11/18 13:00:00'\n",
    "# #datetime_object = datetime.strptime(datetime_str, '%m/%d/%y %H:%M:%S')\n",
    "\n",
    "# if new_df.iloc[0]['contract'] != 'No Recommendations':\n",
    "#     new_df['expiration_date'] = new_df['contract'].apply(lambda x:getContractData(x))\n",
    "#     #2020-08-14 16:00:00\n",
    "#     new_df['expiration_date'] = new_df['expiration_date'].apply(lambda x:datetime.strptime(x+'-UTC', '%Y-%m-%d %H:%M:%S-%Z'))\n",
    "#     #new_df['date_of_recommendation'] = new_df['date_of_recommendation'].apply(lambda x:datetime.strptime(x+' 05:00:00-UTC', '%m/%d/%Y %H:%M:%S-%Z'))\n",
    "#     new_df['date_of_recommendation'] = new_df['date_of_recommendation'].apply(lambda x:datetime.strptime(x+' 05:00:00-UTC', '%Y-%m-%d %H:%M:%S-%Z'))\n",
    "#     #new_df.dtypes\n",
    "# else:\n",
    "#     new_df['expiration_date'] = ''\n",
    "#     new_df['date_of_recommendation'] = new_df['date_of_recommendation'].apply(lambda x:datetime.strptime(x+' 05:00:00-UTC', '%Y-%m-%d %H:%M:%S-%Z'))\n",
    "#     #new_df.dtypes\n",
    "    \n",
    "\n",
    "# len_of_new_df = len(new_df)\n",
    "\n",
    "# new_df = new_df.transpose()\n",
    "# new_df_dict = new_df.to_dict()\n",
    "    \n",
    "# #new_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import firebase_admin\n",
    "# from firebase_admin import credentials\n",
    "# from firebase_admin import firestore\n",
    "\n",
    "# # Use a service account\n",
    "# cred = credentials.Certificate('key.json')\n",
    "# firebase_admin.initialize_app(cred)\n",
    "# db = firestore.client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_the_rec = db.collection(u'test6').where(u\"id\", u'>', 1000).order_by(u\"id\", \"DESCENDING\").limit(1)\n",
    "# newId = -100000\n",
    "\n",
    "# docs = all_the_rec.stream()\n",
    "\n",
    "# for doc in docs:\n",
    "#     newId = int(doc.id) + 1\n",
    "    \n",
    "# print(newId)\n",
    "\n",
    "# for i in range(0, len_of_new_df, 1):\n",
    "#     contract_dict = new_df_dict[i]\n",
    "#     doc_id = newId + i\n",
    "#     contract_dict['id'] = doc_id\n",
    "#     contract_dict['expired'] = False\n",
    "#     #print(contract_dict)\n",
    "#     db.collection(u'test6').document(str(doc_id)).set(contract_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Scope Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TimeSeries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-422b54cf7dc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0metf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msector_etf_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#print(etf)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0msector_sma_rating\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0metf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msector_macd_rating\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0metf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msector_macd_slope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0metf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_sector_ratings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msector_sma_rating\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msector_macd_rating\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msector_macd_slope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-422b54cf7dc7>\u001b[0m in \u001b[0;36mget_sector_ratings\u001b[1;34m(etf, sector_sma_rating, sector_macd_rating, sector_macd_slope)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_sector_ratings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msector_sma_rating\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msector_macd_rating\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msector_macd_slope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ZSAE2CXUXOLE67NH'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pandas'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindexing_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_daily_adjusted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0metf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'full'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmyData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"2. high\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"High\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"3. low\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Low\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"4. close\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"Close\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TimeSeries' is not defined"
     ]
    }
   ],
   "source": [
    "def get_sector_ratings(etf,sector_sma_rating,sector_macd_rating,sector_macd_slope):\n",
    "    \n",
    "    ts = TimeSeries(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "    data, meta_data = ts.get_daily_adjusted(symbol=etf, outputsize='full')\n",
    "    myData = data.rename(index=str, columns={\"2. high\": \"High\", \"3. low\": \"Low\",\"4. close\":\"Close\"})\n",
    "    #print(myData.head())\n",
    "    myDataSimple=myData[['Close']].copy()\n",
    "    myDataSimple['20d'] = np.round(myDataSimple.Close.rolling(window =20, center = False).mean(),2)\n",
    "    myDataSimple['50d'] = np.round(myDataSimple.Close.rolling(window =50, center = False).mean(),2)\n",
    "    myDataSimple['200d'] = np.round(myDataSimple.Close.rolling(window =200, center = False).mean(),2)\n",
    "    sma_rating_today=SMA_rating(myDataSimple)\n",
    "    macd_rating_today,slope=MACD_rating(myDataSimple)\n",
    "    time.sleep(12)\n",
    "    return sma_rating_today,macd_rating_today,slope   \n",
    "\n",
    "\n",
    "for etf in sector_etf_list:\n",
    "    #print(etf)\n",
    "    sector_sma_rating[etf],sector_macd_rating[etf],sector_macd_slope[etf]=get_sector_ratings(etf,sector_sma_rating,sector_macd_rating,sector_macd_slope)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intra_day_data():\n",
    "    ts = TimeSeries(key='ZSAE2CXUXOLE67NH', output_format='pandas')\n",
    "    intra_day_data, meta_data = ts.get_intraday(symbol='MSFT',interval='1min', outputsize='full')\n",
    "    intra_day_data = intra_day_data.rename(index=str, columns={\"2. high\": \"High\", \"3. low\": \"Low\",\"4. close\":\"Close\"})\n",
    "    intra_day_data['20m'] = np.round(intra_day_data.Close.rolling(window =20, center = False).mean(),2)\n",
    "    intra_day_data['50m'] = np.round(intra_day_data.Close.rolling(window =50, center = False).mean(),2)\n",
    "    intra_day_data['200m'] = np.round(intra_day_data.Close.rolling(window =200, center = False).mean(),2)\n",
    "    return intra_day_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMA rating\n",
    "def SMA_rating_intra_day(data_simple):\n",
    "#     start_date = date(1998,1,2)\n",
    "#     yesterday = (datetime.now() - timedelta(days=1))\n",
    "#     end_date = date(yesterday.year,yesterday.month,yesterday.day)\n",
    "    sma_rating = 0\n",
    "    sma_ratings = []\n",
    "    for index,val in enumerate(data_simple['Close']):\n",
    "        if data_simple['Close'][index] > data_simple['50m'][index] > data_simple['200m'][index]:\n",
    "            sma_rating=1\n",
    "        elif data_simple['50m'][index] > data_simple['Close'][index]> data_simple['200m'][index]:\n",
    "            sma_rating=2\n",
    "        elif data_simple['50m'][index] > data_simple['200m'][index] > data_simple['Close'][index]:\n",
    "            sma_rating=3\n",
    "        elif data_simple['200m'][index] > data_simple['50m'][index] > data_simple['Close'][index]:\n",
    "            sma_rating=4\n",
    "        elif data_simple['200m'][index]> data_simple['Close'][index] > data_simple['50m'][index]:\n",
    "            sma_rating=5\n",
    "        elif data_simple['Close'][index] > data_simple['200m'][index] > data_simple['50m'][index]:\n",
    "            sma_rating=6\n",
    "        elif data_simple['Close'][index] > data_simple['50m'][index] > data_simple['200m'][index]:\n",
    "            sma_rating=7\n",
    "        sma_ratings.append(sma_rating)\n",
    "    return sma_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD_rating_intra_day(data_simple):\n",
    "        data_simple['26 ema']=data_simple.Close.ewm(span=26).mean()\n",
    "        data_simple['12 ema']=data_simple.Close.ewm(span=12).mean()\n",
    "        data_simple['9 ema']=data_simple.Close.ewm(span=9).mean()\n",
    "        data_simple['MACD'] = (data_simple['12 ema'] - data_simple['26 ema'])\n",
    "        data_simple['signal_line']=data_simple.MACD.ewm(span=9).mean()\n",
    "        data_simple['hist']=(data_simple['MACD']-data_simple['signal_line'])\n",
    "        #MACD rating\n",
    "        index = len(data_simple.index)-1\n",
    "        macd_rating = 0\n",
    "        macd_ratings = []\n",
    "        for index,val in enumerate(data_simple['Close']):\n",
    "            if data_simple['MACD'][index] > data_simple['signal_line'][index] and data_simple['signal_line'][index] > 0:\n",
    "                macd_rating=1\n",
    "            elif data_simple['signal_line'][index] > data_simple['MACD'][index] and data_simple['MACD'][index] > 0:\n",
    "                macd_rating=2\n",
    "            elif data_simple['MACD'][index] < 0 and 0 < data_simple['signal_line'][index]:\n",
    "                macd_rating=3\n",
    "            elif data_simple['MACD'][index] < data_simple['signal_line'][index] and data_simple['signal_line'][index]< 0:\n",
    "                macd_rating=4\n",
    "            elif data_simple['signal_line'][index] < data_simple['MACD'][index] and data_simple['MACD'][index] < 0:\n",
    "                macd_rating=5\n",
    "            elif data_simple['MACD'][index] > 0 and 0 > data_simple['signal_line'][index]:\n",
    "                macd_rating=6\n",
    "            macd_ratings.append(macd_rating)\n",
    "        return macd_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8021995ab8f2363c1d590aafa608d50d94957792f3fac4b05b55a5254dbc8f23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
