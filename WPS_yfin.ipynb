{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time\n",
      "2021-11-05T04:00:00Z    64.49\n",
      "2021-11-08T05:00:00Z    63.80\n",
      "2021-11-09T05:00:00Z    64.43\n",
      "2021-11-10T05:00:00Z    65.39\n",
      "2021-11-11T05:00:00Z    66.14\n",
      "                        ...  \n",
      "2022-10-31T04:00:00Z    96.98\n",
      "2022-11-01T04:00:00Z    97.53\n",
      "2022-11-02T04:00:00Z    95.80\n",
      "2022-11-03T04:00:00Z    96.28\n",
      "2022-11-04T04:00:00Z    95.19\n",
      "Name: Close, Length: 252, dtype: float64\n",
      "Date\n",
      "01/21/2022    68.94\n",
      "01/24/2022    68.59\n",
      "01/25/2022    68.37\n",
      "01/26/2022    72.27\n",
      "01/27/2022    74.20\n",
      "              ...  \n",
      "10/31/2022    96.98\n",
      "11/01/2022    97.53\n",
      "11/02/2022    95.80\n",
      "11/03/2022    96.28\n",
      "11/04/2022    95.19\n",
      "Name: Close, Length: 200, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Lloyd : All data pre cached here\n",
    "#Lloyd : Norgate can be swapped out here\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "STOCKS         : pd = pd.read_pickle(\"stocks_alpaca.pkl\")\n",
    "STOCKS_1         : pd = pd.read_pickle(\"stocks_nasdaq.pkl\")\n",
    "PACKED_OPTIONS : pd = pd.read_pickle(\"options_packed.pkl\")\n",
    "EARNINGS       : pd = pd.read_pickle(\"earnings.pkl\")\n",
    "\n",
    "print(STOCKS[ STOCKS.Symbol == 'ADM']['Close'])\n",
    "print(STOCKS_1[ STOCKS_1.Symbol == 'ADM']['Close'])\n",
    "\n",
    "# print(STOCKS[ STOCKS.Symbol == 'AMP'])\n",
    "# print(PACKED_OPTIONS)\n",
    "# print(EARNINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "#092321 Modify the TDAmeritrade API get refresh token algo\n",
    "#061121 Hide the TDAmeritrade API credentials\n",
    "#022021 Add controal group to compare the significance of WOO rating  \n",
    "#012721 Adjust earnings date and expiration date comparison method. \n",
    "#011221 Add code to request option contracts data in one shot\n",
    "#010721 Add time delay due to increased number of stocks and TOS limitation.\n",
    "#123120 Add try and except to report function for updating earnings date\n",
    "#121720 Replace RSI from Alpha-Vantage with local function (Alpha-Vantage does not work properly) \n",
    "#110320 Fixed bugs in RSI update frequency and XLC list building.\n",
    "#102220 Add a step to check if the algo uses the most recent data: data_test function\n",
    "#100220 Add a row of 'No Recommendations' to show if the output is empty\n",
    "#090820 Replace source of S&P 500 members' symbols\n",
    "#072720 Add Google Spreadsheet update for AppSheet\n",
    "\n",
    "# using Norgate data\n",
    "# using Yahoo Finance Earning Calendar\n",
    "\n",
    "\n",
    "import norgatedata\n",
    "priceadjust = norgatedata.StockPriceAdjustmentType.TOTALRETURN \n",
    "padding_setting = norgatedata.PaddingType.NONE   \n",
    "timeseriesformat = 'pandas-dataframe'\n",
    "\n",
    "\n",
    "#from alpha_vantage.timeseries import TimeSeries\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "import requests\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import time\n",
    "#import quandl\n",
    "import sys\n",
    "import math\n",
    "from tqdm import tqdm, trange\n",
    "#from alpha_vantage.techindicators import TechIndicators\n",
    "#from datapackage import Package\n",
    "#import urllib.request, json\n",
    "#from pymemcache.client import base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "support1 = 0\n",
    "support2 = 0\n",
    "resistance1 = 0\n",
    "resistance2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def all_time_rsi_values(stock_para):\n",
    "#     ts = TechIndicators(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "#     data, meta_data = ts.get_rsi(symbol=stock_para)\n",
    "#     return data['RSI'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "# def get_earnings_date():\n",
    "#     \"\"\"\n",
    "#     Get earnings dates for a week from today by scraping data from https://api.earningscalendar.net/\n",
    "#     \"\"\"\n",
    "#     start_date = date.today()\n",
    "#     end_date = date.today()+timedelta(5)\n",
    "\n",
    "#     list_4_today=list()\n",
    "#     for single_date in daterange(start_date, end_date):\n",
    "#         time.sleep(5)\n",
    "#         x=single_date.strftime(\"%Y%m%d\")\n",
    "#         urlto_search=\"https://api.earningscalendar.net/?date=\"+x\n",
    "#         with urllib.request.urlopen(urlto_search) as url:\n",
    "#             data = json.loads(url.read().decode())\n",
    "#             for dat in data:\n",
    "#                 list_4_today.append(dat[\"ticker\"])\n",
    "#     return list_4_today\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_all_data(symbol_para):\n",
    "#     symbol = symbol_para\n",
    "#     start_date = '2015-01-01' #ts = TimeSeries(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "#     try:\n",
    "#         #print(symbol_para)\n",
    "#         pricedata_dataframe = norgatedata.price_timeseries(\n",
    "#                     symbol,\n",
    "#                     stock_price_adjustment_setting = priceadjust,\n",
    "#                     padding_setting = padding_setting,\n",
    "#                     start_date = start_date,\n",
    "#                     format=timeseriesformat)\n",
    "#         company_name = norgatedata.security_name(symbol)[:-7]\n",
    "#     except:\n",
    "#         return pd.DataFrame(), str()\n",
    "#     myData = pricedata_dataframe.rename(index=str, columns={\"2. high\": \"High\", \"3. low\": \"Low\",\"4. close\":\"Close\"})\n",
    "#     myData['20d'] = np.round(myData.Close.rolling(window =20, center = False).mean(),2)\n",
    "#     myData['50d'] = np.round(myData.Close.rolling(window =50, center = False).mean(),2)\n",
    "#     myData['200d'] = np.round(myData.Close.rolling(window =200, center = False).mean(),2)\n",
    "#     #print(myData.tail(5))\n",
    "    \n",
    "#     return (myData, company_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lloyd : stocks built in first cell\n",
    "#Lloyd : company names can be appended after\n",
    "\n",
    "def get_all_data(symbol):\n",
    "    myData = STOCKS[ STOCKS.Symbol == symbol ]\n",
    "    myData['20d'] = np.round(myData.Close.rolling(window =20, center = False).mean(),2)\n",
    "    myData['50d'] = np.round(myData.Close.rolling(window =50, center = False).mean(),2)\n",
    "    myData['200d'] = np.round(myData.Close.rolling(window =200, center = False).mean(),2)\n",
    "    \n",
    "    return (myData, 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMA rating\n",
    "def SMA_rating(data_simple):\n",
    "#     start_date = date(1998,1,2)\n",
    "#     yesterday = (datetime.now() - timedelta(days=1))\n",
    "#     end_date = date(yesterday.year,yesterday.month,yesterday.day)\n",
    "    sma_rating = 0\n",
    "    index = len(data_simple.index)-1\n",
    "    if data_simple['Close'][index] > data_simple['50d'][index] > data_simple['200d'][index]:\n",
    "        sma_rating=1\n",
    "    elif data_simple['50d'][index] > data_simple['Close'][index]> data_simple['200d'][index]:\n",
    "        sma_rating=2\n",
    "    elif data_simple['50d'][index] > data_simple['200d'][index] > data_simple['Close'][index]:\n",
    "        sma_rating=3\n",
    "    elif data_simple['200d'][index] > data_simple['50d'][index] > data_simple['Close'][index]:\n",
    "        sma_rating=4\n",
    "    elif data_simple['200d'][index]> data_simple['Close'][index] > data_simple['50d'][index]:\n",
    "        sma_rating=5\n",
    "    elif data_simple['Close'][index] > data_simple['200d'][index] > data_simple['50d'][index]:\n",
    "        sma_rating=6\n",
    "    elif data_simple['Close'][index] > data_simple['50d'][index] > data_simple['200d'][index]:\n",
    "        sma_rating=7\n",
    "    return sma_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD_rating(data_simple):\n",
    "        data_simple['26 ema']=data_simple.Close.ewm(span=26).mean()\n",
    "        data_simple['12 ema']=data_simple.Close.ewm(span=12).mean()\n",
    "        data_simple['MACD'] = (data_simple['12 ema'] - data_simple['26 ema'])\n",
    "        data_simple['signal_line']=data_simple.MACD.ewm(span=9).mean()\n",
    "        data_simple['hist']=(data_simple['MACD']-data_simple['signal_line'])\n",
    "        \n",
    "        #MACD rating\n",
    "        index = len(data_simple)-1\n",
    "        slope = 0\n",
    "        macd_rating = 0\n",
    "        \n",
    "        #print(\"Current MACD:\",data_simple['MACD'][index])\n",
    "        #print(\"Previous day MACD\",data_simple['MACD'][index-1])\n",
    "        \n",
    "        #Condition for the slope\n",
    "        if((data_simple['MACD'][index] - data_simple['MACD'][index-1])>0):\n",
    "            slope = 1\n",
    "        elif((data_simple['MACD'][index] - data_simple['MACD'][index-1])<0):\n",
    "            slope = -1\n",
    "            \n",
    "        #Condition for the MACD rating\n",
    "        if data_simple['MACD'][index] > data_simple['signal_line'][index] and data_simple['signal_line'][index] > 0:\n",
    "            macd_rating=1\n",
    "        elif data_simple['signal_line'][index] > data_simple['MACD'][index] and data_simple['MACD'][index] > 0:\n",
    "            macd_rating=2\n",
    "        elif data_simple['MACD'][index] < 0 and 0 < data_simple['signal_line'][index]:\n",
    "            macd_rating=3\n",
    "        elif data_simple['MACD'][index] < data_simple['signal_line'][index] and data_simple['signal_line'][index]< 0:\n",
    "            macd_rating=4\n",
    "        elif data_simple['signal_line'][index] < data_simple['MACD'][index] and data_simple['MACD'][index] < 0:\n",
    "            macd_rating=5\n",
    "        elif data_simple['MACD'][index] > 0 and 0 > data_simple['signal_line'][index]:\n",
    "            macd_rating=6\n",
    "        return macd_rating,slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_rsi_values(stock, data_simple, n=14):\n",
    "#     ts = TechIndicators(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "#     try:\n",
    "#         data, meta_data = ts.get_rsi(symbol=stock_para, interval='daily') # interval = '1min'\n",
    "#         print('{}\\'s RSI is {}.'.format(stock_para,data['RSI'][-2]))\n",
    "#     except:\n",
    "#         return -1\n",
    "#     if(data.empty):\n",
    "#         return -1\n",
    "#     if(data['RSI'][-1]>70 or data['RSI'][-1]<30):\n",
    "#         ret_val = -1\n",
    "#     else:\n",
    "#         ret_val = 1\n",
    "#     return ret_val\n",
    "   \n",
    "    #def RSI(self, prices, n=14):\n",
    "    \n",
    "    rsi = 0\n",
    "    index = len(data_simple.index)-1\n",
    "    prices = data_simple['Close']\n",
    "    symbol = stock\n",
    "    #print(symbol)\n",
    "    \n",
    "    deltas = np.diff(prices)\n",
    "    #if index >360:\n",
    "    #    seed = deltas[index-360 : index-360 + n+1]\n",
    "    #else:\n",
    "    seed = deltas[:n+1]\n",
    "    up = seed[seed >= 0].sum()/n\n",
    "    down = -seed[seed < 0].sum()/n\n",
    "    rs = up/down\n",
    "    rsi = np.zeros_like(prices)\n",
    "    rsi[:n] = 100. - 100./(1.+rs)\n",
    "\n",
    "    for i in range(n+1, len(prices)):\n",
    "        delta = deltas[i-1]  # The diff is 1 shorter\n",
    "\n",
    "        if delta > 0:\n",
    "            upval = delta\n",
    "            downval = 0.\n",
    "        else:\n",
    "            upval = 0.\n",
    "            downval = -delta\n",
    "\n",
    "        up = (up*(n-1) + upval)/n\n",
    "        down = (down*(n-1) + downval)/n\n",
    "\n",
    "        rs = up/down\n",
    "        rsi[i] = 100. - 100./(1.+rs)\n",
    "        \n",
    "    if(rsi[-1] == False):\n",
    "        print('RSI computing error found.')\n",
    "        return -1\n",
    "    elif(rsi[-1]>70 or rsi[-1]<30):\n",
    "        #print('{}\\'s RSI is {}.'.format(symbol,rsi[-1]))\n",
    "        rsi_rating = -1\n",
    "    else:\n",
    "        rsi_rating = 1\n",
    "        #print('{}\\'s RSI is {}.'.format(symbol,rsi[-1]))\n",
    "\n",
    "    return rsi_rating\n",
    "\n",
    "\n",
    "# 3/5/2020 Charlie suggests this label was wrong. He recommends RSI>40 for 1, and others for -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global Declarations\n",
    "\n",
    "reversal = 3 #reversal amount set to 3 as default\n",
    "\n",
    "# (price range, box size)\n",
    "#function will provide box sizes according to traditional method\n",
    "box_ranges = [(.25,.0625),\n",
    "              (1,.125), \n",
    "              (5,.25),\n",
    "              (20,.5),\n",
    "              (100,1),\n",
    "              (200,2),\n",
    "              (500,4),\n",
    "              (1000,5),\n",
    "              (25000,50),\n",
    "              (sys.maxsize,500)]\n",
    "\n",
    "#to check and update box size according to current value of stock\n",
    "def updateBoxSize(price):\n",
    "    for i in range (len(box_ranges)):\n",
    "        if price < box_ranges[i][0]: #Zhen: Does it return multiple values?\n",
    "            return box_ranges[i][1] \n",
    "    return None\n",
    "\n",
    "\n",
    "#using alpha_vantage because quandl gives only data till March 2018\n",
    "\n",
    "#if current trend is x update x column appropriately or move to o column if needed\n",
    "def updateX(item, list1, list2, box_size, reversal, current_trend, numberofXBoxes, numberofOBoxes):\n",
    "    box_size = updateBoxSize(list1[-1])\n",
    "   # print(math.floor(item[\"High\"]))\n",
    "    if ( math.floor(item[\"High\"]) >= list1[-1]+box_size ):\n",
    "        list1[-1] = math.floor(item[\"High\"])\n",
    "    #   print(\"Updated the x value to:\"+str(list1[-1]))\n",
    "        numberofXBoxes += 1\n",
    "    elif ( math.ceil(item[\"Low\"]) <= list1[-1]-reversal*box_size):\n",
    "        list2.append(math.ceil(item[\"Low\"]))\n",
    "    #   print(\"Updated the o value to:\"+str(list2[-1]))\n",
    "        current_trend = 'o'\n",
    "        numberofOBoxes += 1\n",
    "    return current_trend\n",
    "\n",
    "#if current trend is o update o column appropriately or move to x column if needed\n",
    "def updateO(item, list1, list2, box_size, reversal, current_trend,  numberofXBoxes, numberofOBoxes):\n",
    "    box_size = updateBoxSize(list2[-1])\n",
    "    if ( math.ceil(item[\"Low\"]) <= list2[-1]-box_size ):\n",
    "        list2[-1] = math.ceil(item[\"Low\"])\n",
    "#        print(\"Updated the o value to:\"+str(list2[-1]))\n",
    "        numberofOBoxes += 1\n",
    "    elif ( math.floor(item[\"High\"]) >= list2[-1]+reversal*box_size):\n",
    "        list1.append(math.floor(item[\"High\"]))\n",
    " #       print(\"Updated the x value to:\"+str(list1[-1]))\n",
    "        current_trend = 'x'\n",
    "        numberofXBoxes += 1\n",
    "    return current_trend\n",
    "\n",
    "#create the point and figure from scratch\n",
    "\n",
    "def pointAndFigureCreate(box_size,current_trend, list1, list2, stockhilowdata, numberofXBoxes, numberofOBoxes):\n",
    "    #iterate over each date for the stock and create x or o columns\n",
    "    for index,row in stockhilowdata.iloc[0:].iterrows():\n",
    "        if current_trend == 'x':\n",
    "        #   print(\"The price is:\"+str(row[\"High\"]))\n",
    "            current_trend = updateX(row, list1, list2, box_size, reversal, current_trend, numberofXBoxes, numberofOBoxes)\n",
    "        elif current_trend=='o':\n",
    "            current_trend = updateO(row, list1, list2, box_size, reversal, current_trend, numberofXBoxes, numberofOBoxes)\n",
    "          #  print(\"The price is:\"+str(row[\"Low\"]))\n",
    "    return current_trend\n",
    "\n",
    "#check for a continous triple top pattern\n",
    "def continous_triple_top(current_trend, list1):\n",
    "    if(len(list1)<3):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'x':\n",
    "        if((list1[-1]> list1[-2]) and (list1[-2] == list1[-3])):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "        \n",
    "#check for a continous triple bottom pattern\n",
    "def continous_triple_bottom(current_trend, list2):\n",
    "    if(len(list2)<3):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'o':\n",
    "        if((list2[-1] < list2[-2]) and (list2[-2] == list2[-3])):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "#check for a continous double top pattern\n",
    "def continous_double_top(current_trend, list1):\n",
    "    if(len(list1)<2):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend=='x':\n",
    "        if(list1[-1]> list1[-2]):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "#check for a continous double bottom pattern\n",
    "def continous_double_bottom(current_trend, list2):\n",
    "    if(len(list2)<2):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'o':\n",
    "        if(list2[-1]< list2[-2]):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "def continous_quadruple_top(current_trend, list1):\n",
    "    if(len(list1)<4):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'x' and len(list1)>3:\n",
    "        if((list1[-1] > list1[-2]) and (list1[-2] == list1[-3] == list1[-4])):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "def continous_quadruple_bottom(current_trend, list2):\n",
    "    if(len(list2)<4):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'o' and len(list2)>3:\n",
    "        if((list2[-1] < list2[-2]) and (list2[-2] == list2[-3] == list2[-4])):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "import itertools\n",
    "def spread_triple_top(current_trend, list1):\n",
    "    ret_val = -1\n",
    "    if current_trend == 'x' and len(list1)>7:\n",
    "        iterprev = 0\n",
    "        resistance = 0\n",
    "        notstt = True\n",
    "        for iter in list1[-2:-7:1]:\n",
    "            if iterprev == iter:\n",
    "                resistance = iter\n",
    "                notstt = False\n",
    "            if resistance!=0 and iter > resistance:\n",
    "                notstt = True\n",
    "                break\n",
    "            iterprev = iter\n",
    "        if(notstt == False):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "def spread_triple_bottom(current_trend, list2):\n",
    "    ret_val = -1\n",
    "    if current_trend == 'o' and len(list2)>7:\n",
    "        iterprev = 0\n",
    "        support = 0\n",
    "        notstb = True\n",
    "        for iter in list2[-2:-7:1]:\n",
    "            if iterprev == iter:\n",
    "                support = iter\n",
    "                notstb = False\n",
    "            if support!=0 and iter<resistance:\n",
    "                notstb = True\n",
    "                break\n",
    "            iterprev = iter\n",
    "        if(notstb == False):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "def get_support_levels(list2):\n",
    "    if(len(list2)>=2):\n",
    "        return list2[-1],list2[-2]\n",
    "    elif (len(list2)==1):\n",
    "        return list2[-1],0\n",
    "    else:\n",
    "        return 0,0\n",
    "\n",
    "def get_resistance_levels(list1):\n",
    "    if(len(list1)>=2):\n",
    "        return list1[-1],list1[-2]\n",
    "    elif (len(list1)==1):\n",
    "        return list1[-1],0\n",
    "    else:\n",
    "        return 0,0\n",
    "    \n",
    "    \n",
    "def PnFMain(myData):\n",
    "    #list1 stores the highest value of each x column by index\n",
    "    #list2 stores the lowest value of each o column by index\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "\n",
    "    #current_trend stores the value of the most recent trend. we start off with x as default\n",
    "    current_trend = 'x'\n",
    "\n",
    "    numberofXBoxes = 1 # to get number of x boxes in all\n",
    "    numberofOBoxes = 0 # to get number of o boxes in all\n",
    "\n",
    "    #set box size according to price on day 1\n",
    "    box_size = updateBoxSize(myData[\"High\"].iloc[0])\n",
    "    #append price on day 1 to list1 as we stfart with x\n",
    "    list1.append(math.floor(myData[\"High\"].iloc[0]))\n",
    "    current_trend = pointAndFigureCreate(box_size, current_trend, list1, list2, myData, numberofXBoxes, numberofOBoxes)\n",
    "    ret_val_triple_top = continous_triple_top(current_trend,list1)\n",
    "    ret_val_triple_bottom = continous_triple_bottom(current_trend,list2)\n",
    "    ret_val_double_top = continous_double_top(current_trend,list1)\n",
    "    ret_val_double_bottom = continous_double_bottom(current_trend,list2)\n",
    "    ret_val_quadruple_top = continous_quadruple_top(current_trend,list1)\n",
    "    ret_val_quadruple_bottom = continous_quadruple_bottom(current_trend,list2)\n",
    "    ret_val_spread_triple_top = spread_triple_top(current_trend,list1)\n",
    "    ret_val_spread_triple_bottom = spread_triple_bottom(current_trend,list2)\n",
    "    \n",
    "    global support1\n",
    "    global support2\n",
    "    global resistance1\n",
    "    global resistance2\n",
    "    \n",
    "    support1,support2 = get_support_levels(list2)\n",
    "    resistance1,resistance2 = get_resistance_levels(list1)\n",
    "    \n",
    "    if ret_val_quadruple_top == 1:\n",
    "        return 'a'\n",
    "    elif ret_val_triple_top == 1:\n",
    "        return 'b'\n",
    "    elif ret_val_double_top == 1:\n",
    "        return 'c'\n",
    "    elif ret_val_quadruple_bottom == 1:\n",
    "        return 'd'\n",
    "    elif ret_val_triple_bottom == 1:\n",
    "        return 'e'\n",
    "    elif ret_val_double_bottom == 1:\n",
    "        return 'f'\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sector_etf_list=['XLF']\\nsector_sma_rating={'XLF':0}\\nsector_macd_rating={'XLF':0}\\nsector_macd_slope={'XLF':0}\\nsector_pnf_rating={'XLF':0}\\nsector_rsi_rating={'XLF':0}\\nsector_etf_to_names={'XLF':financial_list}\""
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_list=list()\n",
    "energy_list=list()\n",
    "industrial_list=list()\n",
    "comm_services_list=list()\n",
    "materials_list=list()\n",
    "health_list=list()\n",
    "consumer_list=list()\n",
    "technology_list=list()\n",
    "consumer_stap_list=list()\n",
    "\n",
    "sector_etf_list=['XLF','XLE','XLI','XLC','XLB','XLV','XLY','XLK','XLP']\n",
    "sector_sma_rating={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_macd_rating={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_macd_slope={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_pnf_rating={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_rsi_rating={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_etf_to_names={'XLF':financial_list,'XLE':energy_list,'XLI':industrial_list,'XLC':comm_services_list,'XLB':materials_list,'XLV':health_list,'XLY':consumer_list,'XLK':technology_list,'XLP':consumer_stap_list}\n",
    "\n",
    "\n",
    "\"\"\"sector_etf_list=['XLF']\n",
    "sector_sma_rating={'XLF':0}\n",
    "sector_macd_rating={'XLF':0}\n",
    "sector_macd_slope={'XLF':0}\n",
    "sector_pnf_rating={'XLF':0}\n",
    "sector_rsi_rating={'XLF':0}\n",
    "sector_etf_to_names={'XLF':financial_list}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code uses datahub.io to collect S&P500 members' symbols.\n",
    "#\n",
    "#package = Package('https://datahub.io/core/s-and-p-500-companies/datapackage.json')\n",
    "# for resource in package.resources:\n",
    "#     if resource.descriptor['datahub']['type'] == 'derived/csv':\n",
    "#         my_list=resource.read()\n",
    "# df = pd.DataFrame(my_list, columns=['Symbol','Name','Sector'])\n",
    "\n",
    "\n",
    "\n",
    "# This code uses wikipedia.org to collect S&P members' symbols\n",
    "\n",
    "import pandas as pd\n",
    "table = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies', header = 0)\n",
    "df1 = table[0]\n",
    "\n",
    "df = df1[['Symbol', 'Security', 'GICS Sector']]\n",
    "\n",
    "df = df.rename(columns = {\"GICS Sector\":'Sector'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df['Sector'][i]=='Industrials':\n",
    "        industrial_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Health Care':\n",
    "        health_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Energy':\n",
    "        energy_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Financials':\n",
    "        financial_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Information Technology':\n",
    "        technology_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Consumer Discretionary':\n",
    "        consumer_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Materials':\n",
    "        materials_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Communication Services':\n",
    "        comm_services_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Consumer Staples':\n",
    "        consumer_stap_list.append(df['Symbol'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_test():\n",
    "#     \"\"\"Check the integrety of data.\"\"\"\n",
    "#     from pandas.tseries.offsets import BDay\n",
    "\n",
    "#     today = datetime.today()\n",
    "#     LastBday = today - BDay(1)\n",
    "\n",
    "#     print('The last business date is {}.'.format(LastBday.date()))\n",
    "#     testData, symbol = get_all_data('SPY') \n",
    "#     #print(type(testData.index[-1]))\n",
    "#     data_date = datetime.strptime(testData.index[-1], \"%Y-%m-%d %H:%M:%S\")\n",
    "#     #print(data_date.date())\n",
    "#     print('The last date in data is {}.'.format(data_date.date())) #format(data_date) #.date())\n",
    "\n",
    "#     if data_date.date() != LastBday.date():\n",
    "#         print('\\n ###################################################################### \\n \\\n",
    "# #  The last business day\\'s data is incorrect. Check the data source. # \\n\\\n",
    "#  ######################################################################')\n",
    "#         raise SystemExit\n",
    "#     else:\n",
    "#         print('The last business day\\'s data is correct. You can proceed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLF:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:02<00:16,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLE:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:02<00:11,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLI:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:04<00:10,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLC:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:05<00:07,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLB:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:06<00:05,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLV:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:08<00:04,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLY:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:10<00:03,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLK:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:12<00:01,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLP:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:13<00:00,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''Get data for applying ratings.'''\n",
    "df_rated_now = pd.DataFrame()\n",
    "\n",
    "for sector in tqdm(sector_etf_list):\n",
    "    print(sector+':', end = '')\n",
    "    for i in range(0,len(sector_etf_to_names[sector])):        \n",
    "        myData, company_name = get_all_data(sector_etf_to_names[sector][i])            \n",
    "        if(not myData.empty):\n",
    "\n",
    "            if (not myData.Close.isnull().values.any()):\n",
    "\n",
    "                myData = myData.tail(200)\n",
    "\n",
    "                macd_rating,slope = MACD_rating(myData)\n",
    "                df_rated_now = df_rated_now.append({'Stock Symbol':sector_etf_to_names[sector][i], \n",
    "                                                'Company Name': company_name, \n",
    "                                                'SMA':SMA_rating(myData), \n",
    "                                                'MACD':macd_rating,\n",
    "                                                'MACD Slope':slope, \n",
    "                                                'PnF':PnFMain(myData), \n",
    "                                                'RSI':daily_rsi_values(sector_etf_to_names[sector][i], myData), \n",
    "                                                'Support1':support1, 'Support2':support2,'Resistance1':resistance1, 'Resistance2':resistance2 }, \n",
    "                                                ignore_index=True)\n",
    "        else:\n",
    "            print('Data for stock is not present in the API')\n",
    "    #print(df_rated_now)\n",
    "\n",
    "print('Done')\n",
    "\n",
    "\n",
    "# df_rated_now[df_rated_now['Stock Symbol']=='FBHS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rated_now.to_csv('Rated_Stocks_All.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define contral groupo\n",
    "# Randomly choose 20 stocks from the full list of stocks\n",
    "\n",
    "df_control = df_rated_now.sample(n=40)\n",
    "\n",
    "df_control = df_control.rename(columns={\"Stock Symbol\":\"Symbol\"})\n",
    "\n",
    "# df_control.to_csv(r'C:\\Users\\User\\Box\\WOOatUB\\YashaAbhinavRohit\\Stock_List_Control.csv')\n",
    "\n",
    "# df_control.to_csv(r'C:\\Users\\User\\Box\\WOOatUB\\YashaAbhinavRohit\\ContractsData\\\\'+ datetime.today().strftime('%Y-%m-%d')+'_control''.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD Slope</th>\n",
       "      <th>PnF</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Resistance1</th>\n",
       "      <th>Resistance2</th>\n",
       "      <th>SMA</th>\n",
       "      <th>Stock Symbol</th>\n",
       "      <th>Support1</th>\n",
       "      <th>Support2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N/A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AFL</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N/A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ALL</td>\n",
       "      <td>120.0</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N/A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AXP</td>\n",
       "      <td>139.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N/A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>AIG</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N/A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AMP</td>\n",
       "      <td>302.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company Name  MACD  MACD Slope   PnF  RSI  Resistance1  Resistance2  SMA  \\\n",
       "0          N/A   1.0         1.0     c -1.0         68.0         60.0  1.0   \n",
       "1          N/A   4.0         1.0     c  1.0        129.0        127.0  6.0   \n",
       "2          N/A   5.0         1.0  None  1.0        146.0        149.0  4.0   \n",
       "3          N/A   1.0         1.0     c -1.0         58.0         51.0  6.0   \n",
       "4          N/A   1.0         1.0  None  1.0        319.0        319.0  1.0   \n",
       "\n",
       "  Stock Symbol  Support1  Support2  \n",
       "0          AFL      57.0      57.0  \n",
       "1          ALL     120.0     117.0  \n",
       "2          AXP     139.0     133.0  \n",
       "3          AIG      48.0      48.0  \n",
       "4          AMP     302.0     258.0  "
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from alpha_vantage.timeseries import TimeSeries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "#import quandl\n",
    "import sys\n",
    "import math\n",
    "#from alpha_vantage.techindicators import TechIndicators\n",
    "#from datapackage import Package\n",
    "import urllib.request, json\n",
    "#from pymemcache.client import base\n",
    "\n",
    "# Location = r'Rated_Stocks_All.csv'\n",
    "# df_rated_now = pd.read_csv(Location)\n",
    "df_rated_now.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_final_list():\n",
    "    final_list = []\n",
    "    pnf_list = ['a','b','c']\n",
    "    for index,row in df_rated_now.iloc[0:].iterrows():\n",
    "        if row['MACD'] == 1 and row['MACD Slope'] == 1 and row['SMA'] == 1 and row['PnF'] in pnf_list and row['RSI'] == 1:\n",
    "            row_data = {'Symbol':row['Stock Symbol'] , 'Company Name':row['Company Name'], 'Score':row['PnF'], 'Support1':row['Support1'],'Support2':row['Support2'],'Resistance1':row['Resistance1'],'Resistance2':row['Resistance2']}\n",
    "            final_list.append(row_data)\n",
    "    final_df = pd.DataFrame(final_list)\n",
    "    if not final_df.empty:\n",
    "        final_df['SymbolKey'] = final_df['Symbol']\n",
    "        final_df.set_index('SymbolKey', inplace = True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_close_price(stock_list):\n",
    "    '''For Point and Figure rating'''\n",
    "    close_price = list()\n",
    "    for row in stock_list.iterrows():\n",
    "        symbol = row[1]['Symbol']\n",
    "        #print(\"Symbol is:\", symbol)\n",
    "            #symbol = symbol_para\n",
    "        start_date = '2010-01-01' #ts = TimeSeries(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "        try:\n",
    "            pricedata_dataframe = norgatedata.price_timeseries(\n",
    "                    symbol,\n",
    "                    stock_price_adjustment_setting = priceadjust,\n",
    "                    padding_setting = padding_setting,\n",
    "                    start_date = start_date,\n",
    "                    format=timeseriesformat)\n",
    "            close_price.append(pricedata_dataframe['Close'].iloc[-1])\n",
    "        except:\n",
    "            close_price.append(-1)\n",
    "    stock_list['Close Price']=close_price\n",
    "    return stock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def next_earnings_date(symbol):\n",
    "#     # Use Yahoo Finance Earnings Calendar https://github.com/wenboyu2/yahoo-earnings-calendar\n",
    "#     from datetime import datetime\n",
    "#     from yahoo_earnings_calendar import YahooEarningsCalendar\n",
    "#     my_custom_delay_s = 0.5\n",
    "#     #try:\n",
    "#     yec = YahooEarningsCalendar(my_custom_delay_s)# Returns the next earnings date of BOX in Unix timestamp\n",
    "#     ts = yec.get_next_earnings_date(symbol)\n",
    "#     return datetime.fromtimestamp(ts)\n",
    "#     #except:\n",
    "#         #print(symbol)\n",
    "#     #    print('Situation: ' + symbol + 'Invalid Symbol or Unavailable Earnings Date')\n",
    "#         #return datetime.fromtimestamp(ts)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lloyd : will fetch from dataframe in first cell\n",
    "# \n",
    "def next_earnings_date(symbol):\n",
    "    # Use Yahoo Finance Earnings Calendar https://github.com/wenboyu2/yahoo-earnings-calendar\n",
    "    return  EARNINGS[ EARNINGS.index == symbol].iloc[0]['date'] \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-01-30 16:00:00')"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_earnings_date('GOOGL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_five_global = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "# import csv\n",
    "# import pandas as pd\n",
    "# from pandas.io.json import json_normalize\n",
    "# from datetime import datetime  \n",
    "# from datetime import timedelta\n",
    "# import logging\n",
    "\n",
    "# import config as cf\n",
    "\n",
    "\n",
    "# # Following code makes relevant tokens necessary to conduct TD ameritrade activities on behalf of Zhen Liu's personal account\n",
    "# # Note refresh token is valid for 90 days. It is used to generate auth token which is only valid for 30 mins\n",
    "# def get_auth_token():\n",
    "#     auth_params = {'grant_type':'refresh_token', 'refresh_token':cf.refresh_token, 'client_id': cf.client_id}\n",
    "#     auth_api_url = 'https://api.tdameritrade.com/v1/oauth2/token'\n",
    "#     headers = {'Content-Type': \"application/x-www-form-urlencoded\"}\n",
    "#     data =  requests.post(auth_api_url, headers = headers, data=auth_params).json()\n",
    "#     #print(data)\n",
    "#     result = \"Bearer \"+ data['access_token']\n",
    "\n",
    "#     return result\n",
    "\n",
    "# # Following code will get the option chain data using the authorized token\n",
    "# # Parameters: call_or_put: 'CALL'/'PUT'; symbol: string with stock symbol from passed in stock list\n",
    "# def get_raw_option_data(call_or_put, symbol):\n",
    "#     url = 'https://api.tdameritrade.com/v1/marketdata/chains'\n",
    "#     strike_count = '100' #need to figure out how to get ALL or just use an arbitraliy huge num\n",
    "#     strategy = 'SINGLE'\n",
    "#     authorization_header = {'Authorization': get_auth_token()}\n",
    "#     pay = {'symbol':symbol,'strikeCount':strike_count , 'strategy':strategy}\n",
    "#     if call_or_put == \"CALL\":\n",
    "#         return [requests.get(url, params = pay, headers = authorization_header).json()['callExpDateMap'], \n",
    "#                 requests.get(url, params = pay, headers = authorization_header).json()['underlyingPrice']]\n",
    "#     elif call_or_put == \"PUT\":\n",
    "#         return [requests.get(url, params = pay, headers = authorization_header).json()['putExpDateMap'], requests.get(url, params = pay, headers = authorization_header).json()['underlyingPrice']]\n",
    "\n",
    "\n",
    "\n",
    "# # Following code does the filtering of the options data based on our chosen parameters\n",
    "# def processing(symbol, Option_Data, supp1,supp2, params, call_or_put):\n",
    "#     data = Option_Data[symbol]\n",
    "#     agg_data = {}\n",
    "#     date_keys = []\n",
    "#     for (k,v) in data[0].items():\n",
    "#         date_keys.append([k,list(v.keys())])\n",
    "#         agg_data[k] = v\n",
    "        \n",
    "#     #If there is no data regarding some symbol in API then just return an empty dataframe\n",
    "#     if not date_keys:\n",
    "#         return pd.DataFrame()\n",
    "        \n",
    "#     target_list = []\n",
    "#     stock_price = data[1]\n",
    "    \n",
    "#     if call_or_put == \"CALL\":\n",
    "#         for i in range(0,len(date_keys)):\n",
    "#             for j in range(0, len(date_keys[i][1])):\n",
    "#                 if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] < params['days_min'] or agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] > params['days_max']: # Days to Expiration Requirement!\n",
    "#                     continue\n",
    "#                 if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] < params['bid_min']: # Min/Max Bid requirement!\n",
    "#                     continue\n",
    "#                 if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['totalVolume'] < params['min_vol']: # Min/Max Volume Requirement!\n",
    "#                     continue\n",
    "#                 if (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price) / stock_price < params['%OTM_lim']: # Percent OTM Requirement!\n",
    "#                     continue\n",
    "#                 if 1 - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'] < params['prob_OTM_lim']: # Prob OTM Requirement!\n",
    "#                     continue\n",
    "#                 support = 0\n",
    "#                 if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']<supp1 and agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']>supp2:\n",
    "#                     support = 1\n",
    "#                 # construct a dictionary object characteristics we want and append to list\n",
    "#                 target = {'stock': symbol,\n",
    "#                          'contract': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['symbol'],\n",
    "#                          'strike_price':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'],\n",
    "#                          'stock_price':stock_price,\n",
    "#                          'days_to_exp':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'],\n",
    "#                          'bid': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'],\n",
    "#                          'ask': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['ask'],\n",
    "#                          'last': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['last'],\n",
    "#                          'prob_OTM': 1 - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'],\n",
    "#                          '% OTM': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price) / stock_price,\n",
    "#                          'cov_ret': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['mark']-((stock_price - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'])/stock_price)*(365/agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration']),\n",
    "#                          'max_cov_ret': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['mark']+((agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price)/stock_price)*(365/agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration']),\n",
    "#                          'prob_touch': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta']*2,\n",
    "#                          'annual_return': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['ask'] * 365 * 100)/((agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']) * (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'])),\n",
    "#                          'btwn_supports':support}\n",
    "#                 target_list.append(target)\n",
    "#     elif call_or_put == \"PUT\":\n",
    "#         for i in range(0,len(date_keys)):\n",
    "#             for j in range(0, len(date_keys[i][1])):\n",
    "#                 if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] < params['days_min'] or \\\n",
    "#                 agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] > params['days_max']: # Days to Expiration Requirement!\n",
    "#                     continue\n",
    "#                 if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] < params['bid_min']: # Min/Max Bid requirement!\n",
    "#                     continue\n",
    "#                 if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['totalVolume'] < params['min_vol']: # Min/Max Volume Requirement!\n",
    "#                     continue\n",
    "#                 if (stock_price - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']) / \\\n",
    "#                 stock_price < params['%OTM_lim']: \n",
    "#                     # Percent OTM Requirement!\n",
    "#                     continue\n",
    "#                 prob_otm = 1 + float(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'])\n",
    "#                 #print(\"The prob of OTM is\", round(prob_otm, 2))\n",
    "#                 #print(\"The otm limit is\", params['prob_OTM_lim'])\n",
    "#                 if prob_otm < params['prob_OTM_lim']: # Prob OTM Requirement!      + or -???\n",
    "#                     #print(\"The prob of OTM\", round(prob_otm, 2))\n",
    "#                     continue\n",
    "#                 if (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] - \\\n",
    "#                           max(0, (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - \\\n",
    "#                             stock_price)))/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']- \\\n",
    "#                                            agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid']) * 365 * 100/\\\n",
    "#                            agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] < \\\n",
    "#                             params['annual_ptnl_ret_lim']: # Covered return Requirement! \n",
    "#                     continue\n",
    "#                 if float(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'])*(-2) > \\\n",
    "#                 params['prob_touch_lim']: # Probability of touching parameter      + or - ???\n",
    "#                     continue\n",
    "#                 support = 0\n",
    "#                 if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']<supp1 and agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']>supp2:\n",
    "#                     support = 1\n",
    "# #Commented code checks for 24% annual return. If required in future\n",
    "# #                 value = (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid']*365*100)/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']*agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'])\n",
    "# #                 if value<15:\n",
    "# #                     continue\n",
    "    \n",
    "#                 # Construct a dictionary object characteristics we want and append to list\n",
    "#                 target = {'stock':symbol,\n",
    "#                          'contract':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['symbol'],\n",
    "#                          'strike_price':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'],\n",
    "#                          'stock_price':stock_price,\n",
    "#                          'days_to_exp':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'],\n",
    "#                          'bid': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'],\n",
    "#                          'ask': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['ask'],\n",
    "#                          'last': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['last'],\n",
    "#                          'prob_OTM': 1 + float(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta']), # + or - ???\n",
    "#                          '% OTM': 1-agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']/stock_price,\n",
    "#                          'ptnl_ret': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] - \\\n",
    "#                           max(0, (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - \\\n",
    "#                             stock_price)))/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']- \\\n",
    "#                                            agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid']),\n",
    "#                          'annual_ptnl_ret': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] - \\\n",
    "#                           max(0, (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - \\\n",
    "#                             stock_price)))/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']- \\\n",
    "#                                            agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid']) * 365 * 100/\\\n",
    "#                            agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'],\n",
    "\n",
    "#                          'prob_touch': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta']*(-2),\n",
    "#                          'btwn_supports': support}# + or - ???\n",
    "                \n",
    "# #                 print(\"The value of accepted delta\",target['prob_OTM'])\n",
    "#                 target_list.append(target)\n",
    "#     df = pd.DataFrame(target_list)\n",
    "#     if(df.empty):\n",
    "#         print('Got empty')\n",
    "#         return df\n",
    "#     df = df.set_index('contract', drop = True)\n",
    "#     return df\n",
    "\n",
    "\n",
    "\n",
    "# # Following function returns price data for a stock which can be used to construct a P&F chart\n",
    "# # def return_candle_data(symbol):\n",
    "# #     candle_url = 'https://api.tdameritrade.com/v1/marketdata/'+symbol+'/pricehistory'\n",
    "# #     candle_header = {'Authorization': get_auth_token()}\n",
    "# #     # Vary the properties below depending on how often you want the data\n",
    "# #     # Ideally, we want to set up a web socket to continuously stream this data?\n",
    "# #     period_type = 'day'\n",
    "# #     period = 2\n",
    "# #     freq_type = 'minute'\n",
    "# #     freq = 1\n",
    "# #     candle_payload = {'periodType': period_type, 'period': period, 'frequencyType': freq_type, 'frequency': freq}\n",
    "# #     raw_candle_data = requests.get(candle_url, params = candle_payload, headers = candle_header).json()\n",
    "# #     df = pd.DataFrame(raw_candle_data['candles'])\n",
    "# #     return df\n",
    "\n",
    "\n",
    "# def report(stock_list, Option_Data, put_parameters):\n",
    "#     # Select by WOO ratings and earnings dates criteria\n",
    "    \n",
    "#     df_top_five_all =  pd.DataFrame()\n",
    "    \n",
    "#     d0 = date.today()\n",
    "    \n",
    "#     for row in tqdm(stock_list.iterrows()):\n",
    "#         item = row[1]['Symbol']\n",
    "#         supp1 = row[1]['Support1']\n",
    "#         supp2 = row[1]['Support2']\n",
    "#         name = row[1]['Company Name']\n",
    "#         print(item, end=\" \")\n",
    "#         df = processing(item, Option_Data, supp1,supp2, put_parameters, \"PUT\")\n",
    "#         if(not df.empty):\n",
    "#             df_top_five = df.sort_values(by=['annual_ptnl_ret'], ascending=False)\n",
    "#             df_top_five = df_top_five.head(5)\n",
    "#             df_top_five['company name'] = name\n",
    "#             if df_top_five_all.empty:\n",
    "#                 df_top_five_all = df_top_five\n",
    "#             else:\n",
    "#                 df_top_five_all = df_top_five_all.append(df_top_five)\n",
    "#         #time.sleep(5)\n",
    "                \n",
    "#     if(not df_top_five_all.empty):\n",
    "#         df_top_five_all = df_top_five_all.sort_values(by=['btwn_supports','stock','annual_ptnl_ret'], ascending=[False,True,False])\n",
    "        \n",
    "#         df_top_five_all['Days to Earnings'] = '!' # In case earnings date data is not avaialbe, avoid reporting the contracts.\n",
    "        \n",
    "#         df_top_five_all['Risk level'] = put_parameters['label']\n",
    "        \n",
    "#         for index, row in df_top_five_all.iterrows():\n",
    "            \n",
    "#             try:\n",
    "#                 ed = next_earnings_date(row['stock']).date()\n",
    "#                 delta = ed - d0 #compute dates from today to earnings date\n",
    "#                 #print(delta.days)\n",
    "#                 print('The next earnings date of {} is {}.'.format(row['stock'],ed))\n",
    "           \n",
    "#                 #if delta.days>0: # Yahoo may report earning dates that just passed.\n",
    "#                 d_days = delta.days - row['days_to_exp']                \n",
    "\n",
    "#                 if (d_days <= 0):\n",
    "#                     df_top_five_all = df_top_five_all.drop(index, axis=0)\n",
    "#                 else:\n",
    "#                     df_top_five_all.at[index, 'Days to Earnings']= delta.days\n",
    "#             except:\n",
    "#                 print('Error happens in finding the next earnings data.')\n",
    "#                 df_top_five_all = df_top_five_all.drop(index, axis=0)\n",
    "#                 pass\n",
    "\n",
    "#     else:\n",
    "#         print(\"No contracts available in the {} criteria.\".format(put_parameters['label']))\n",
    "    \n",
    "#     return df_top_five_all    \n",
    "               \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime  \n",
    "from datetime import timedelta\n",
    "import logging\n",
    "\n",
    "import config as cf\n",
    "\n",
    "\n",
    "# Following code will get the option chain data using the authorized token\n",
    "# Parameters: call_or_put: 'CALL'/'PUT'; symbol: string with stock symbol from passed in stock list\n",
    "def get_raw_option_data(call_or_put, symbol):\n",
    "\n",
    "    option : dict = json.loads( PACKED_OPTIONS[ PACKED_OPTIONS[\"Symbol\"] == symbol ]['Json'].iloc[0] )\n",
    "\n",
    "    return option\n",
    "\n",
    "\n",
    "# Following code does the filtering of the options data based on our chosen parameters\n",
    "def processing(symbol, Option_Data, supp1,supp2, params, call_or_put):\n",
    "    data = Option_Data[symbol]\n",
    "    agg_data = {}\n",
    "    date_keys = []\n",
    "    for (k,v) in data[0].items():\n",
    "        date_keys.append([k,list(v.keys())])\n",
    "        agg_data[k] = v\n",
    "        \n",
    "    #If there is no data regarding some symbol in API then just return an empty dataframe\n",
    "    if not date_keys:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    target_list = []\n",
    "    stock_price = data[1]\n",
    "    \n",
    "    if call_or_put == \"CALL\":\n",
    "        for i in range(0,len(date_keys)):\n",
    "            for j in range(0, len(date_keys[i][1])):\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] < params['days_min'] or agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] > params['days_max']: # Days to Expiration Requirement!\n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] < params['bid_min']: # Min/Max Bid requirement!\n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['totalVolume'] < params['min_vol']: # Min/Max Volume Requirement!\n",
    "                    continue\n",
    "                if (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price) / stock_price < params['%OTM_lim']: # Percent OTM Requirement!\n",
    "                    continue\n",
    "                if 1 - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'] < params['prob_OTM_lim']: # Prob OTM Requirement!\n",
    "                    continue\n",
    "                support = 0\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']<supp1 and agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']>supp2:\n",
    "                    support = 1\n",
    "                # construct a dictionary object characteristics we want and append to list\n",
    "                target = {'stock': symbol,\n",
    "                         'contract': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['symbol'],\n",
    "                         'strike_price':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'],\n",
    "                         'stock_price':stock_price,\n",
    "                         'days_to_exp':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'],\n",
    "                         'bid': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'],\n",
    "                         'ask': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['ask'],\n",
    "                         'last': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['last'],\n",
    "                         'prob_OTM': 1 - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'],\n",
    "                         '% OTM': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price) / stock_price,\n",
    "                         'cov_ret': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['mark']-((stock_price - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'])/stock_price)*(365/agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration']),\n",
    "                         'max_cov_ret': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['mark']+((agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price)/stock_price)*(365/agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration']),\n",
    "                         'prob_touch': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta']*2,\n",
    "                         'annual_return': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['ask'] * 365 * 100)/((agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']) * (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'])),\n",
    "                         'btwn_supports':support}\n",
    "                target_list.append(target)\n",
    "    elif call_or_put == \"PUT\":\n",
    "        for i in range(0,len(date_keys)):\n",
    "            for j in range(0, len(date_keys[i][1])):\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] < params['days_min'] or \\\n",
    "                agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] > params['days_max']: # Days to Expiration Requirement!\n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] < params['bid_min']: # Min/Max Bid requirement!\n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['totalVolume'] < params['min_vol']: # Min/Max Volume Requirement!\n",
    "                    continue\n",
    "                if (stock_price - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']) / \\\n",
    "                stock_price < params['%OTM_lim']: \n",
    "                    # Percent OTM Requirement!\n",
    "                    continue\n",
    "                prob_otm = 1 + float(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'])\n",
    "                #print(\"The prob of OTM is\", round(prob_otm, 2))\n",
    "                #print(\"The otm limit is\", params['prob_OTM_lim'])\n",
    "                if prob_otm < params['prob_OTM_lim']: # Prob OTM Requirement!      + or -???\n",
    "                    #print(\"The prob of OTM\", round(prob_otm, 2))\n",
    "                    continue\n",
    "                if (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] - \\\n",
    "                          max(0, (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - \\\n",
    "                            stock_price)))/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']- \\\n",
    "                                           agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid']) * 365 * 100/\\\n",
    "                           agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] < \\\n",
    "                            params['annual_ptnl_ret_lim']: # Covered return Requirement! \n",
    "                    continue\n",
    "                if float(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'])*(-2) > \\\n",
    "                params['prob_touch_lim']: # Probability of touching parameter      + or - ???\n",
    "                    continue\n",
    "                support = 0\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']<supp1 and agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']>supp2:\n",
    "                    support = 1\n",
    "#Commented code checks for 24% annual return. If required in future\n",
    "#                 value = (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid']*365*100)/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']*agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'])\n",
    "#                 if value<15:\n",
    "#                     continue\n",
    "    \n",
    "                # Construct a dictionary object characteristics we want and append to list\n",
    "                target = {'stock':symbol,\n",
    "                         'contract':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['symbol'],\n",
    "                         'strike_price':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'],\n",
    "                         'stock_price':stock_price,\n",
    "                         'days_to_exp':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'],\n",
    "                         'bid': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'],\n",
    "                         'ask': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['ask'],\n",
    "                         'last': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['last'],\n",
    "                         'prob_OTM': 1 + float(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta']), # + or - ???\n",
    "                         '% OTM': 1-agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']/stock_price,\n",
    "                         'ptnl_ret': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] - \\\n",
    "                          max(0, (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - \\\n",
    "                            stock_price)))/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']- \\\n",
    "                                           agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid']),\n",
    "                         'annual_ptnl_ret': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] - \\\n",
    "                          max(0, (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - \\\n",
    "                            stock_price)))/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']- \\\n",
    "                                           agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid']) * 365 * 100/\\\n",
    "                           agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'],\n",
    "\n",
    "                         'prob_touch': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta']*(-2),\n",
    "                         'btwn_supports': support}# + or - ???\n",
    "                \n",
    "#                 print(\"The value of accepted delta\",target['prob_OTM'])\n",
    "                target_list.append(target)\n",
    "    df = pd.DataFrame(target_list)\n",
    "    if(df.empty):\n",
    "        print('Got empty')\n",
    "        return df\n",
    "    df = df.set_index('contract', drop = True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Following function returns price data for a stock which can be used to construct a P&F chart\n",
    "# def return_candle_data(symbol):\n",
    "#     candle_url = 'https://api.tdameritrade.com/v1/marketdata/'+symbol+'/pricehistory'\n",
    "#     candle_header = {'Authorization': get_auth_token()}\n",
    "#     # Vary the properties below depending on how often you want the data\n",
    "#     # Ideally, we want to set up a web socket to continuously stream this data?\n",
    "#     period_type = 'day'\n",
    "#     period = 2\n",
    "#     freq_type = 'minute'\n",
    "#     freq = 1\n",
    "#     candle_payload = {'periodType': period_type, 'period': period, 'frequencyType': freq_type, 'frequency': freq}\n",
    "#     raw_candle_data = requests.get(candle_url, params = candle_payload, headers = candle_header).json()\n",
    "#     df = pd.DataFrame(raw_candle_data['candles'])\n",
    "#     return df\n",
    "\n",
    "\n",
    "def report(stock_list, Option_Data, put_parameters):\n",
    "    # Select by WOO ratings and earnings dates criteria\n",
    "    \n",
    "    df_top_five_all =  pd.DataFrame()\n",
    "    \n",
    "    d0 = date.today()\n",
    "    \n",
    "    for row in tqdm(stock_list.iterrows()):\n",
    "        item = row[1]['Symbol']\n",
    "        supp1 = row[1]['Support1']\n",
    "        supp2 = row[1]['Support2']\n",
    "        name = row[1]['Company Name']\n",
    "        print(item, end=\" \")\n",
    "        df = processing(item, Option_Data, supp1,supp2, put_parameters, \"PUT\")\n",
    "        if(not df.empty):\n",
    "            df_top_five = df.sort_values(by=['annual_ptnl_ret'], ascending=False)\n",
    "            df_top_five = df_top_five.head(5)\n",
    "            df_top_five['company name'] = name\n",
    "            if df_top_five_all.empty:\n",
    "                df_top_five_all = df_top_five\n",
    "            else:\n",
    "                df_top_five_all = df_top_five_all.append(df_top_five)\n",
    "        #time.sleep(5)\n",
    "                \n",
    "    if(not df_top_five_all.empty):\n",
    "        df_top_five_all = df_top_five_all.sort_values(by=['btwn_supports','stock','annual_ptnl_ret'], ascending=[False,True,False])\n",
    "        \n",
    "        df_top_five_all['Days to Earnings'] = '!' # In case earnings date data is not avaialbe, avoid reporting the contracts.\n",
    "        \n",
    "        df_top_five_all['Risk level'] = put_parameters['label']\n",
    "        \n",
    "        for index, row in df_top_five_all.iterrows():\n",
    "            \n",
    "            try:\n",
    "                ed = next_earnings_date(row['stock']).date()\n",
    "                delta = ed - d0 #compute dates from today to earnings date\n",
    "                #print(delta.days)\n",
    "                print('The next earnings date of {} is {}.'.format(row['stock'],ed))\n",
    "           \n",
    "                #if delta.days>0: # Yahoo may report earning dates that just passed.\n",
    "                d_days = delta.days - row['days_to_exp']                \n",
    "\n",
    "                if (d_days <= 0):\n",
    "                    df_top_five_all = df_top_five_all.drop(index, axis=0)\n",
    "                else:\n",
    "                    df_top_five_all.at[index, 'Days to Earnings']= delta.days\n",
    "            except:\n",
    "                print(f\"{row['stock']}: Error happens in finding the next earnings data.\")\n",
    "                df_top_five_all = df_top_five_all.drop(index, axis=0)\n",
    "                pass\n",
    "\n",
    "    else:\n",
    "        print(\"No contracts available in the {} criteria.\".format(put_parameters['label']))\n",
    "    \n",
    "    return df_top_five_all    \n",
    "               \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final stock list is done.\n"
     ]
    }
   ],
   "source": [
    "stock_list = get_final_list() # Need to populate this array with stock list we derive from technical indicators\n",
    "#earnings_df = earnings_dates()\n",
    "#print('Earnings List:',earnings_df)\n",
    "#print('Stock List Before:', stock_list)\n",
    "\n",
    "# stock_list.to_csv(r'C:\\Users\\User\\Box\\WOOatUB\\YashaAbhinavRohit\\Stock_List.csv')\n",
    "\n",
    "# stock_list.to_csv(r'C:\\Users\\User\\Box\\WOOatUB\\YashaAbhinavRohit\\ContractsData\\\\'+ datetime.today().strftime('%Y-%m-%d')+'.csv')\n",
    "\n",
    "if stock_list.empty == 0:\n",
    "    stock_list.sort_values(by=['Score'], ascending = False)    \n",
    "    stock_list = get_close_price(stock_list)\n",
    "    print('Final stock list is done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity\n",
    "stock_list.to_csv(\"yfin_stock_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AJG CBOE Got empty\n",
      "COP "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 283.33it/s]\n",
      "17it [00:00, 448.05it/s]\n",
      "17it [00:00, 548.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRO MPC OXY FTV Got empty\n",
      "IEX Got empty\n",
      "PWR SNA Got empty\n",
      "GWW APD MCK GPC Got empty\n",
      "MSI PTC Got empty\n",
      "MNST The next earnings date of GWW is 2023-02-02.\n",
      "The next earnings date of MCK is 2023-01-31.\n",
      "The next earnings date of MNST is 2022-11-03.\n",
      "The next earnings date of MNST is 2022-11-03.\n",
      "The next earnings date of MSI is 2022-11-03.\n",
      "The next earnings date of PWR is 2022-11-03.\n",
      "The next earnings date of PWR is 2022-11-03.\n",
      "The next earnings date of AJG is 2023-01-25.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of MCK is 2023-01-31.\n",
      "The next earnings date of MCK is 2023-01-31.\n",
      "The next earnings date of MCK is 2023-01-31.\n",
      "The next earnings date of MCK is 2023-01-31.\n",
      "The next earnings date of MNST is 2022-11-03.\n",
      "The next earnings date of MNST is 2022-11-03.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MRO is 2022-11-03.\n",
      "The next earnings date of MRO is 2022-11-03.\n",
      "The next earnings date of MRO is 2022-11-03.\n",
      "The next earnings date of MRO is 2022-11-03.\n",
      "The next earnings date of MRO is 2022-11-03.\n",
      "The next earnings date of MSI is 2022-11-03.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "AJG Got empty\n",
      "CBOE Got empty\n",
      "COP MRO MPC OXY FTV Got empty\n",
      "IEX Got empty\n",
      "PWR Got empty\n",
      "SNA Got empty\n",
      "GWW Got empty\n",
      "APD MCK Got empty\n",
      "GPC Got empty\n",
      "MSI PTC Got empty\n",
      "MNST Got empty\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of MSI is 2022-11-03.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of MRO is 2022-11-03.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "The next earnings date of OXY is 2022-11-08.\n",
      "AJG Got empty\n",
      "CBOE Got empty\n",
      "COP MRO Got empty\n",
      "MPC OXY FTV Got empty\n",
      "IEX Got empty\n",
      "PWR Got empty\n",
      "SNA Got empty\n",
      "GWW Got empty\n",
      "APD MCK Got empty\n",
      "GPC Got empty\n",
      "MSI Got empty\n",
      "PTC Got empty\n",
      "MNST Got empty\n",
      "The next earnings date of APD is 2023-02-02.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of COP is 2023-02-01.\n",
      "The next earnings date of MPC is 2023-01-31.\n",
      "The next earnings date of OXY is 2022-11-08.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# #df['EA'][0]\n",
    "# Date_Keys = []\n",
    "# Agg_Data = {}\n",
    "\n",
    "# for (k,v) in df['ULTA'][0].items():\n",
    "#     date_keys.append([k,list(v.keys())])\n",
    "#     agg_data[k] = v\n",
    "    \n",
    "    \n",
    "# Set selection parameters\n",
    "safe_put_parameters = {'days_min': 1, 'days_max': 60, 'bid_min':0.25, 'bid_max': 10000000, 'min_vol': 5, \\\n",
    "                       'max_vol': 1000000000, '%OTM_lim': 0.0, 'prob_OTM_lim': 0.95, 'annual_ptnl_ret_lim': 0.01, \\\n",
    "                       'prob_touch_lim': 0.9, 'label': 'safe'}\n",
    "mod_put_parameters = {'days_min': 1, 'days_max': 60, 'bid_min':0.25, 'bid_max': 10000000, 'min_vol': 5, \\\n",
    "                      'max_vol': 1000000000, '%OTM_lim': 0.0, 'prob_OTM_lim': 0.90, 'annual_ptnl_ret_lim': 0.01, \\\n",
    "                      'prob_touch_lim': 0.9, 'label': 'moderate'}\n",
    "risky_put_parameters = {'days_min': 1, 'days_max': 60, 'bid_min':0.25, 'bid_max': 10000000, 'min_vol': 5, \\\n",
    "                        'max_vol': 1000000000, '%OTM_lim': 0.0, 'prob_OTM_lim': 0.80, 'annual_ptnl_ret_lim': 0.01, \\\n",
    "                        'prob_touch_lim': 0.9, 'label': 'risky'}\n",
    "\n",
    "# Collect option data\n",
    "\n",
    "data = {}\n",
    "\n",
    "for row in stock_list.iterrows():\n",
    "    item = row[1]['Symbol'] \n",
    "    #print(item)\n",
    "    data_entry = get_raw_option_data('PUT', item)\n",
    "    # print(data_entry)\n",
    "    data.update({item: data_entry})\n",
    "    # time.sleep(2)\n",
    "    \n",
    "Option_Data = pd.DataFrame(data)\n",
    "\n",
    "# Generating recommendations\n",
    "df_risky = report(stock_list, Option_Data, risky_put_parameters)\n",
    "\n",
    "df_mod = report(stock_list, Option_Data, mod_put_parameters)\n",
    "\n",
    "df_safe = report(stock_list, Option_Data, safe_put_parameters)\n",
    "\n",
    "\n",
    "Frames = [df_risky, df_mod, df_safe]\n",
    "\n",
    "# Collect option data\n",
    "\n",
    "# data = {}\n",
    "\n",
    "# for row in df_control.iterrows():\n",
    "#     item = row[1]['Symbol'] \n",
    "#     #print(item)\n",
    "#     data_entry = get_raw_option_data('PUT', item)\n",
    "#     data.update({item: data_entry})\n",
    "#     # time.sleep(2)\n",
    "    \n",
    "# Option_Data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# # Generating control group\n",
    "\n",
    "# df_risky = report(df_control, Option_Data, risky_put_parameters)\n",
    "\n",
    "# df_mod = report(df_control, Option_Data, mod_put_parameters)\n",
    "\n",
    "# df_safe = report(df_control, Option_Data, safe_put_parameters)\n",
    "\n",
    "\n",
    "# Frames_Control = [df_risky, df_mod, df_safe]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index          contract stock  strike_price  stock_price  days_to_exp  \\\n",
      "0       0    GWW_111822P560   GWW         560.0      593.640           13   \n",
      "1       1  MCK_111122P382.5   MCK         382.5      389.250            6   \n",
      "2       2    AJG_111822P175   AJG         175.0      189.025           13   \n",
      "3       3    APD_111822P260   APD         260.0      276.375           13   \n",
      "4       4    APD_121622P250   APD         250.0      276.375           41   \n",
      "5       6    APD_121622P240   APD         240.0      276.375           41   \n",
      "6       8    COP_111122P126   COP         126.0      130.875            6   \n",
      "7       9    COP_111122P125   COP         125.0      130.875            6   \n",
      "8      10    COP_111122P124   COP         124.0      130.875            6   \n",
      "9      11    COP_111122P123   COP         123.0      130.875            6   \n",
      "10     12    COP_120222P120   COP         120.0      130.875           27   \n",
      "11     13    MCK_111122P380   MCK         380.0      389.250            6   \n",
      "12     14  MCK_111122P377.5   MCK         377.5      389.250            6   \n",
      "13     15    MCK_112522P365   MCK         365.0      389.250           20   \n",
      "14     16    MCK_112522P360   MCK         360.0      389.250           20   \n",
      "15     17    MPC_111122P112   MPC         112.0      117.980            6   \n",
      "16     18    MPC_111822P110   MPC         110.0      117.980           13   \n",
      "17     19    MPC_111122P111   MPC         111.0      117.980            6   \n",
      "18     20    MPC_111822P109   MPC         109.0      117.980           13   \n",
      "19     21    MPC_111122P110   MPC         110.0      117.980            6   \n",
      "20     22    COP_112522P115   COP         115.0      130.875           20   \n",
      "21     23    COP_111822P115   COP         115.0      130.875           13   \n",
      "22     24    APD_111822P250   APD         250.0      276.375           13   \n",
      "23     26    APD_121622P230   APD         230.0      276.375           41   \n",
      "24     27    COP_111122P122   COP         122.0      130.875            6   \n",
      "25     28    COP_111122P121   COP         121.0      130.875            6   \n",
      "26     29    COP_111822P116   COP         116.0      130.875           13   \n",
      "27     30    MPC_111122P109   MPC         109.0      117.980            6   \n",
      "28     31    MPC_120222P101   MPC         101.0      117.980           27   \n",
      "29     32     MPC_121622P95   MPC          95.0      117.980           41   \n",
      "30     34    APD_111822P240   APD         240.0      276.375           13   \n",
      "31     35    COP_121622P100   COP         100.0      130.875           41   \n",
      "32     36   COP_121622P97.5   COP          97.5      130.875           41   \n",
      "33     37     COP_121622P95   COP          95.0      130.875           41   \n",
      "34     38     MPC_121622P90   MPC          90.0      117.980           41   \n",
      "\n",
      "     bid   ask  last  prob_OTM     % OTM  ptnl_ret  annual_ptnl_ret  \\\n",
      "0   3.30  4.90  4.84     0.813  0.056667  0.005928        16.643407   \n",
      "1   1.40  3.10  2.88     0.802  0.017341  0.003674        22.347590   \n",
      "2   0.60  0.90  0.75     0.880  0.074197  0.003440         9.659492   \n",
      "3   1.40  2.15  1.56     0.828  0.059249  0.005414        15.200190   \n",
      "4   2.65  3.30  3.30     0.832  0.095432  0.010714         9.537685   \n",
      "5   1.70  2.05  1.90     0.891  0.131615  0.007134         6.350880   \n",
      "6   0.84  1.03  0.94     0.800  0.037249  0.006711        40.827740   \n",
      "7   0.68  0.86  0.79     0.830  0.044890  0.005470        33.274346   \n",
      "8   0.55  0.71  1.01     0.857  0.052531  0.004455        27.102741   \n",
      "9   0.44  0.59  0.84     0.880  0.060172  0.003590        21.839643   \n",
      "10  1.68  1.86  2.11     0.808  0.083095  0.014199        19.194651   \n",
      "11  1.05  2.65  2.43     0.826  0.023764  0.002771        16.855786   \n",
      "12  0.80  2.30  1.44     0.848  0.030186  0.002124        12.919211   \n",
      "13  1.45  3.10  2.90     0.863  0.062299  0.003988         7.278916   \n",
      "14  1.10  2.65  2.25     0.888  0.075145  0.003065         5.593480   \n",
      "15  0.61  0.72  0.69     0.820  0.050687  0.005476        33.313882   \n",
      "16  1.03  1.13  0.99     0.800  0.067639  0.009452        26.538709   \n",
      "17  0.48  0.56  0.45     0.854  0.059163  0.004343        26.420557   \n",
      "18  0.87  0.96  0.77     0.827  0.076115  0.008046        22.590329   \n",
      "19  0.37  0.44  0.40     0.883  0.067639  0.003375        20.531181   \n",
      "20  0.60  0.74  0.40     0.906  0.121299  0.005245         9.571678   \n",
      "21  0.34  0.46  0.41     0.931  0.121299  0.002965         8.325618   \n",
      "22  0.65  0.85  1.00     0.921  0.095432  0.002607         7.319029   \n",
      "23  0.90  1.45  1.40     0.931  0.167797  0.003928         3.497248   \n",
      "24  0.36  0.48  0.40     0.900  0.067813  0.002960        18.003946   \n",
      "25  0.28  0.39  0.35     0.918  0.075454  0.002319        14.109786   \n",
      "26  0.40  0.52  0.61     0.922  0.113658  0.003460         9.715198   \n",
      "27  0.28  0.35  0.26     0.907  0.076115  0.002575        15.667157   \n",
      "28  0.62  0.73  0.59     0.904  0.143923  0.006177         8.349752   \n",
      "29  0.68  0.74  0.69     0.921  0.194779  0.007209         6.418213   \n",
      "30  0.30  0.55  0.43     0.957  0.131615  0.001252         3.514008   \n",
      "31  0.49  0.59  0.55     0.950  0.235912  0.004924         4.383675   \n",
      "32  0.38  0.50  0.50     0.959  0.255014  0.003913         3.483244   \n",
      "33  0.35  0.43  0.38     0.965  0.274117  0.003698         3.291974   \n",
      "34  0.42  0.48  0.41     0.950  0.237159  0.004689         4.173950   \n",
      "\n",
      "    prob_touch  btwn_supports company name Days to Earnings Risk level  \\\n",
      "0        0.374              1          N/A               87      risky   \n",
      "1        0.396              1          N/A               85      risky   \n",
      "2        0.240              0          N/A               79      risky   \n",
      "3        0.344              0          N/A               87      risky   \n",
      "4        0.336              0          N/A               87      risky   \n",
      "5        0.218              0          N/A               87      risky   \n",
      "6        0.400              0          N/A               86      risky   \n",
      "7        0.340              0          N/A               86      risky   \n",
      "8        0.286              0          N/A               86      risky   \n",
      "9        0.240              0          N/A               86      risky   \n",
      "10       0.384              0          N/A               86      risky   \n",
      "11       0.348              0          N/A               85      risky   \n",
      "12       0.304              0          N/A               85      risky   \n",
      "13       0.274              0          N/A               85      risky   \n",
      "14       0.224              0          N/A               85      risky   \n",
      "15       0.360              0          N/A               85      risky   \n",
      "16       0.400              0          N/A               85      risky   \n",
      "17       0.292              0          N/A               85      risky   \n",
      "18       0.346              0          N/A               85      risky   \n",
      "19       0.234              0          N/A               85      risky   \n",
      "20       0.188              1          N/A               86   moderate   \n",
      "21       0.138              1          N/A               86   moderate   \n",
      "22       0.158              0          N/A               87   moderate   \n",
      "23       0.138              0          N/A               87   moderate   \n",
      "24       0.200              0          N/A               86   moderate   \n",
      "25       0.164              0          N/A               86   moderate   \n",
      "26       0.156              0          N/A               86   moderate   \n",
      "27       0.186              0          N/A               85   moderate   \n",
      "28       0.192              0          N/A               85   moderate   \n",
      "29       0.158              0          N/A               85   moderate   \n",
      "30       0.086              0          N/A               87       safe   \n",
      "31       0.100              0          N/A               86       safe   \n",
      "32       0.082              0          N/A               86       safe   \n",
      "33       0.070              0          N/A               86       safe   \n",
      "34       0.100              0          N/A               85       safe   \n",
      "\n",
      "   Date of recommendation  \n",
      "0              2022-11-07  \n",
      "1              2022-11-07  \n",
      "2              2022-11-07  \n",
      "3              2022-11-07  \n",
      "4              2022-11-07  \n",
      "5              2022-11-07  \n",
      "6              2022-11-07  \n",
      "7              2022-11-07  \n",
      "8              2022-11-07  \n",
      "9              2022-11-07  \n",
      "10             2022-11-07  \n",
      "11             2022-11-07  \n",
      "12             2022-11-07  \n",
      "13             2022-11-07  \n",
      "14             2022-11-07  \n",
      "15             2022-11-07  \n",
      "16             2022-11-07  \n",
      "17             2022-11-07  \n",
      "18             2022-11-07  \n",
      "19             2022-11-07  \n",
      "20             2022-11-07  \n",
      "21             2022-11-07  \n",
      "22             2022-11-07  \n",
      "23             2022-11-07  \n",
      "24             2022-11-07  \n",
      "25             2022-11-07  \n",
      "26             2022-11-07  \n",
      "27             2022-11-07  \n",
      "28             2022-11-07  \n",
      "29             2022-11-07  \n",
      "30             2022-11-07  \n",
      "31             2022-11-07  \n",
      "32             2022-11-07  \n",
      "33             2022-11-07  \n",
      "34             2022-11-07  \n"
     ]
    }
   ],
   "source": [
    "def final_result(frames):\n",
    "    '''Generate final results'''\n",
    "    df = pd.concat(frames)\n",
    "    df.reset_index(inplace = True)\n",
    "\n",
    "    for i in df.index:\n",
    "        '''Managing the duplcation of contracts at different risky levels'''\n",
    "        #print(df.iloc[i]['Risk level']) #.values[0] == 'risky')\n",
    "        if df.loc[i,'Risk level'] in  ['moderate', 'Moderate']:\n",
    "            try:\n",
    "                index_names = df[(df['Risk level'].isin(['Risky', 'risky'])) & \\\n",
    "                                 (df['contract'] == df.loc[i,'contract'])].index\n",
    "                df.drop(index_names, inplace = True)\n",
    "\n",
    "            except:\n",
    "                print('Something is wrong when removing moderate contracts from risky ones.')\n",
    "\n",
    "    for i in df.index:\n",
    "        if df.loc[i,'Risk level'] in ['Safe', 'safe']:\n",
    "            try:\n",
    "                index_names = df[(df['Risk level'].isin(['moderate', 'Moderate']))\\\n",
    "                                 & (df['contract'] == df.loc[i,'contract'])].index\n",
    "                df.drop(index_names, inplace = True)\n",
    "            except:\n",
    "                print('Something is wrong when removing safe contracts from moderate ones.')\n",
    "\n",
    "    df['Date of recommendation'] = datetime.today().strftime('%Y-%m-%d') # add the date of recommendation column\n",
    "\n",
    "    df.reset_index(inplace = True)\n",
    "\n",
    "    #df.set_index('contract', inplace = True)\n",
    "\n",
    "    if len(df) == 0:\n",
    "        no_rec_dict = {'index': '0000',\n",
    "                       'contract': ['No Recommendations'],\n",
    "                       'stock': ['No Recommendations'],\n",
    "                       'strike_price':[np.nan],\n",
    "                       'stock_price':[np.nan],\n",
    "                       'days_to_exp':[np.nan],\n",
    "                       'bid': [np.nan],\n",
    "                       'ask': [np.nan],\n",
    "                       'last': [np.nan],\n",
    "                       'prob_OTM': [np.nan],\n",
    "                       '% OTM': [np.nan],\n",
    "                       'ptnl_ret': [np.nan],\n",
    "                       'annual_ptnl_ret': [np.nan],\n",
    "                       'prob_touch': [np.nan],\n",
    "                       'btwn_supports': [np.nan],\n",
    "                       'company name': [''],\n",
    "                       'Days to Earnings': [np.nan],\n",
    "                       'Risk level': [''], \n",
    "                       'Date of recommendation': [datetime.today().strftime('%Y-%m-%d')]               \n",
    "                         }\n",
    "        df_no_rec = pd.DataFrame.from_dict(no_rec_dict)\n",
    "        #print(df)\n",
    "        df = df.append(df_no_rec)\n",
    "    return df\n",
    "\n",
    "result_df = final_result(Frames)\n",
    "print(result_df)\n",
    "\n",
    "# result_df.to_csv(r'C:\\Users\\User\\Box\\WOOatUB\\YashaAbhinavRohit\\ContractsData\\'' + datetime.today().strftime('%Y-%m-%d')+'_final_list.csv')\n",
    "\n",
    "# result_df_control = final_result(Frames_Control)\n",
    "# result_df_control.to_csv(r'C:\\Users\\User\\Box\\WOOatUB\\YashaAbhinavRohit\\ContractsData\\'' + datetime.today().strftime('%Y-%m-%d')+'_final_list_control.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity\n",
    "result_df.to_csv(\"yfin_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import gspread\n",
    "# from oauth2client.service_account import ServiceAccountCredentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update to Google Sheet \n",
    "\n",
    "# Mert's Google Sheet\n",
    "# scope = [\"https://spreadsheets.google.com/feeds\",'https://www.googleapis.com/auth/spreadsheets',\"https://www.googleapis.com/auth/drive.file\",\"https://www.googleapis.com/auth/drive\"]\n",
    "# creds = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json', scope)\n",
    "# client = gspread.authorize(creds)\n",
    "\n",
    "# print(\"Started fetching data\")\n",
    "# sheet =  client.open(\"Algo_Recommendations\").worksheet(\"All_The_Recommendations\")\n",
    "# print(\"Data fetching completed\")\n",
    "\n",
    "# for i in result_df.index:\n",
    "#     values = [ str(i), str(result_df.loc[i,'contract']), str(result_df.loc[i,'% OTM']), \\\n",
    "#               str(result_df.loc[i,'annual_ptnl_ret']), str(result_df.loc[i,'ask']), str(result_df.loc[i,'bid']), \\\n",
    "#               str(result_df.loc[i,'btwn_supports']), str(result_df.loc[i,'days_to_exp']), str(result_df.loc[i,'last']), \n",
    "#               str(result_df.loc[i,'prob_OTM']), str(result_df.loc[i,'prob_touch']), str(result_df.loc[i,'ptnl_ret']), \n",
    "#               str(result_df.loc[i,'stock']), str(result_df.loc[i,'stock_price']), str(result_df.loc[i,'strike_price']), str(result_df.loc[i,'company name']), \n",
    "#               str(result_df.loc[i,'Days to Earnings']), str(result_df.loc[i,'Risk level']), str(result_df.loc[i,'Date of recommendation'])]\n",
    "#     #print(values)\n",
    "#     sheet.append_row(values) # we cannot send more than 100 contracts per 5 minutes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Mert's Google Server\n",
    "\n",
    "#df=pd.read_csv('2020-08-11_final_list.csv')\n",
    "# new_df=result_df.rename(columns={'% OTM':'percentage_OTM', 'company name':'company_name', \n",
    "#                           'Days to Earnings': 'days_to_earnings', 'Risk level': 'risk_level', \n",
    "#                           'Date of recommendation': 'date_of_recommendation'})\n",
    "# print(new_df)\n",
    "\n",
    "\n",
    "# def convertDateToTDAmeritradeDate(date):\n",
    "#     month = date[0] + date[1];\n",
    "#     day = date[2] + date[3];\n",
    "#     year = \"20\" + date[4] + date[5];\n",
    "\n",
    "#     return year + \"-\" + month + \"-\" + day + \" 16:00:00\";\n",
    "\n",
    "\n",
    "# def getContractData(contract):\n",
    "#     name_and_rest = contract.split(\"_\");\n",
    "#     date_and_strike = name_and_rest[1].split(\"P\");\n",
    "#     date = convertDateToTDAmeritradeDate(date_and_strike[0]);\n",
    "#     #print(date)\n",
    "#     return date;\n",
    "\n",
    "# #datetime_str = '08/11/18 13:00:00'\n",
    "# #datetime_object = datetime.strptime(datetime_str, '%m/%d/%y %H:%M:%S')\n",
    "\n",
    "# if new_df.iloc[0]['contract'] != 'No Recommendations':\n",
    "#     new_df['expiration_date'] = new_df['contract'].apply(lambda x:getContractData(x))\n",
    "#     #2020-08-14 16:00:00\n",
    "#     new_df['expiration_date'] = new_df['expiration_date'].apply(lambda x:datetime.strptime(x+'-UTC', '%Y-%m-%d %H:%M:%S-%Z'))\n",
    "#     #new_df['date_of_recommendation'] = new_df['date_of_recommendation'].apply(lambda x:datetime.strptime(x+' 05:00:00-UTC', '%m/%d/%Y %H:%M:%S-%Z'))\n",
    "#     new_df['date_of_recommendation'] = new_df['date_of_recommendation'].apply(lambda x:datetime.strptime(x+' 05:00:00-UTC', '%Y-%m-%d %H:%M:%S-%Z'))\n",
    "#     #new_df.dtypes\n",
    "# else:\n",
    "#     new_df['expiration_date'] = ''\n",
    "#     new_df['date_of_recommendation'] = new_df['date_of_recommendation'].apply(lambda x:datetime.strptime(x+' 05:00:00-UTC', '%Y-%m-%d %H:%M:%S-%Z'))\n",
    "#     #new_df.dtypes\n",
    "    \n",
    "\n",
    "# len_of_new_df = len(new_df)\n",
    "\n",
    "# new_df = new_df.transpose()\n",
    "# new_df_dict = new_df.to_dict()\n",
    "    \n",
    "#new_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import firebase_admin\n",
    "# from firebase_admin import credentials\n",
    "# from firebase_admin import firestore\n",
    "\n",
    "# # Use a service account\n",
    "# cred = credentials.Certificate('key.json')\n",
    "# firebase_admin.initialize_app(cred)\n",
    "# db = firestore.client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_the_rec = db.collection(u'test6').where(u\"id\", u'>', 1000).order_by(u\"id\", \"DESCENDING\").limit(1)\n",
    "# newId = -100000\n",
    "\n",
    "# docs = all_the_rec.stream()\n",
    "\n",
    "# for doc in docs:\n",
    "#     newId = int(doc.id) + 1\n",
    "    \n",
    "# print(newId)\n",
    "\n",
    "# for i in range(0, len_of_new_df, 1):\n",
    "#     contract_dict = new_df_dict[i]\n",
    "#     doc_id = newId + i\n",
    "#     contract_dict['id'] = doc_id\n",
    "#     contract_dict['expired'] = False\n",
    "#     #print(contract_dict)\n",
    "#     db.collection(u'test6').document(str(doc_id)).set(contract_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Scope Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sector_ratings(etf,sector_sma_rating,sector_macd_rating,sector_macd_slope):\n",
    "    \n",
    "#     ts = TimeSeries(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "#     data, meta_data = ts.get_daily_adjusted(symbol=etf, outputsize='full')\n",
    "#     myData = data.rename(index=str, columns={\"2. high\": \"High\", \"3. low\": \"Low\",\"4. close\":\"Close\"})\n",
    "#     #print(myData.head())\n",
    "#     myDataSimple=myData[['Close']].copy()\n",
    "#     myDataSimple['20d'] = np.round(myDataSimple.Close.rolling(window =20, center = False).mean(),2)\n",
    "#     myDataSimple['50d'] = np.round(myDataSimple.Close.rolling(window =50, center = False).mean(),2)\n",
    "#     myDataSimple['200d'] = np.round(myDataSimple.Close.rolling(window =200, center = False).mean(),2)\n",
    "#     sma_rating_today=SMA_rating(myDataSimple)\n",
    "#     macd_rating_today,slope=MACD_rating(myDataSimple)\n",
    "#     time.sleep(12)\n",
    "#     return sma_rating_today,macd_rating_today,slope   \n",
    "\n",
    "\n",
    "# for etf in sector_etf_list:\n",
    "#     #print(etf)\n",
    "#     sector_sma_rating[etf],sector_macd_rating[etf],sector_macd_slope[etf]=get_sector_ratings(etf,sector_sma_rating,sector_macd_rating,sector_macd_slope)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_intra_day_data():\n",
    "#     ts = TimeSeries(key='ZSAE2CXUXOLE67NH', output_format='pandas')\n",
    "#     intra_day_data, meta_data = ts.get_intraday(symbol='MSFT',interval='1min', outputsize='full')\n",
    "#     intra_day_data = intra_day_data.rename(index=str, columns={\"2. high\": \"High\", \"3. low\": \"Low\",\"4. close\":\"Close\"})\n",
    "#     intra_day_data['20m'] = np.round(intra_day_data.Close.rolling(window =20, center = False).mean(),2)\n",
    "#     intra_day_data['50m'] = np.round(intra_day_data.Close.rolling(window =50, center = False).mean(),2)\n",
    "#     intra_day_data['200m'] = np.round(intra_day_data.Close.rolling(window =200, center = False).mean(),2)\n",
    "#     return intra_day_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMA rating\n",
    "# def SMA_rating_intra_day(data_simple):\n",
    "# #     start_date = date(1998,1,2)\n",
    "# #     yesterday = (datetime.now() - timedelta(days=1))\n",
    "# #     end_date = date(yesterday.year,yesterday.month,yesterday.day)\n",
    "#     sma_rating = 0\n",
    "#     sma_ratings = []\n",
    "#     for index,val in enumerate(data_simple['Close']):\n",
    "#         if data_simple['Close'][index] > data_simple['50m'][index] > data_simple['200m'][index]:\n",
    "#             sma_rating=1\n",
    "#         elif data_simple['50m'][index] > data_simple['Close'][index]> data_simple['200m'][index]:\n",
    "#             sma_rating=2\n",
    "#         elif data_simple['50m'][index] > data_simple['200m'][index] > data_simple['Close'][index]:\n",
    "#             sma_rating=3\n",
    "#         elif data_simple['200m'][index] > data_simple['50m'][index] > data_simple['Close'][index]:\n",
    "#             sma_rating=4\n",
    "#         elif data_simple['200m'][index]> data_simple['Close'][index] > data_simple['50m'][index]:\n",
    "#             sma_rating=5\n",
    "#         elif data_simple['Close'][index] > data_simple['200m'][index] > data_simple['50m'][index]:\n",
    "#             sma_rating=6\n",
    "#         elif data_simple['Close'][index] > data_simple['50m'][index] > data_simple['200m'][index]:\n",
    "#             sma_rating=7\n",
    "#         sma_ratings.append(sma_rating)\n",
    "#     return sma_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MACD_rating_intra_day(data_simple):\n",
    "#         data_simple['26 ema']=data_simple.Close.ewm(span=26).mean()\n",
    "#         data_simple['12 ema']=data_simple.Close.ewm(span=12).mean()\n",
    "#         data_simple['9 ema']=data_simple.Close.ewm(span=9).mean()\n",
    "#         data_simple['MACD'] = (data_simple['12 ema'] - data_simple['26 ema'])\n",
    "#         data_simple['signal_line']=data_simple.MACD.ewm(span=9).mean()\n",
    "#         data_simple['hist']=(data_simple['MACD']-data_simple['signal_line'])\n",
    "#         #MACD rating\n",
    "#         index = len(data_simple.index)-1\n",
    "#         macd_rating = 0\n",
    "#         macd_ratings = []\n",
    "#         for index,val in enumerate(data_simple['Close']):\n",
    "#             if data_simple['MACD'][index] > data_simple['signal_line'][index] and data_simple['signal_line'][index] > 0:\n",
    "#                 macd_rating=1\n",
    "#             elif data_simple['signal_line'][index] > data_simple['MACD'][index] and data_simple['MACD'][index] > 0:\n",
    "#                 macd_rating=2\n",
    "#             elif data_simple['MACD'][index] < 0 and 0 < data_simple['signal_line'][index]:\n",
    "#                 macd_rating=3\n",
    "#             elif data_simple['MACD'][index] < data_simple['signal_line'][index] and data_simple['signal_line'][index]< 0:\n",
    "#                 macd_rating=4\n",
    "#             elif data_simple['signal_line'][index] < data_simple['MACD'][index] and data_simple['MACD'][index] < 0:\n",
    "#                 macd_rating=5\n",
    "#             elif data_simple['MACD'][index] > 0 and 0 > data_simple['signal_line'][index]:\n",
    "#                 macd_rating=6\n",
    "#             macd_ratings.append(macd_rating)\n",
    "#         return macd_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8021995ab8f2363c1d590aafa608d50d94957792f3fac4b05b55a5254dbc8f23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
